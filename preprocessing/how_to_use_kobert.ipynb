{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설치\n",
    "\n",
    "pip install torch\n",
    "\n",
    "pip install mxnet\n",
    "\n",
    "pip install gluonnlp==0.8.0\n",
    "\n",
    "0.9.1은 이유를 모르겠는데 설치가 안되더라고요\n",
    "\n",
    "pip install sentencepiece\n",
    "\n",
    "pip install onnxruntime\n",
    "\n",
    "pip install transformers\n",
    "\n",
    "pip install kobert-transformers\n",
    "\n",
    "### kobert-transformers 사이트\n",
    "\n",
    "https://pypi.org/project/kobert-transformers/\n",
    "\n",
    "https://github.com/monologg/KoBERT-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.181952Z",
     "start_time": "2020-08-09T22:03:55.385143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golds\\AppData\\Roaming\\Python\\Python37\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import mxnet\n",
    "import gluonnlp\n",
    "import sentencepiece\n",
    "import onnxruntime\n",
    "import transformers\n",
    "import kobert_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.194939Z",
     "start_time": "2020-08-09T22:04:07.183944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch :  1.6.0\n",
      "mxnet :  1.6.0\n",
      "gluonnlp :  0.8.0\n",
      "onnxruntime :  1.4.0\n",
      "transformers :  3.0.2\n",
      "kobert_transformers :  0.4.1\n"
     ]
    }
   ],
   "source": [
    "print('torch : ', torch.__version__)\n",
    "print('mxnet : ', mxnet.__version__)\n",
    "print('gluonnlp : ', gluonnlp.__version__)\n",
    "# print('sentencepiece : ', sentencepiece.__version__)\n",
    "print('onnxruntime : ', onnxruntime.__version__) \n",
    "print('transformers : ', transformers.__version__)\n",
    "print('kobert_transformers : ', kobert_transformers.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.304079Z",
     "start_time": "2020-08-09T22:04:07.198935Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시로 사용할 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.409704Z",
     "start_time": "2020-08-09T22:04:07.307074Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./news_cleaned.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.565184Z",
     "start_time": "2020-08-09T22:04:07.412697Z"
    }
   },
   "outputs": [],
   "source": [
    "query = cur.execute('SELECT * FROM daumnews LIMIT 0, 1000')\n",
    "cols = [column[0] for column in query.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.714489Z",
     "start_time": "2020-08-09T22:04:07.568184Z"
    }
   },
   "outputs": [],
   "source": [
    "daum = pd.DataFrame.from_records(data=query.fetchall(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.770791Z",
     "start_time": "2020-08-09T22:04:07.716482Z"
    }
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.870924Z",
     "start_time": "2020-08-09T22:04:07.774780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"벌금과 단속 걱정하던 아들, 장사 준비하던 현수막으로 목 메 숨져\"결혼까지 미루고 식당 영업재개할 생각에 청소까지 열심히 했는데···\"\n",
      "\n",
      " \"아버지 아들인게 정말 행복했습니다. 이 가게가 잘 될 수 있도록 수호신이 될게요\"\n",
      "26살 황승우씨는 지난 30일 오전 경기 남양주시 조안면 막국수집 주방에서 목을 메 숨진 채 발견됐다. 이곳은 아버지 황선남(65)씨와 지난 2015년 희망을 품고 문을 연 가게였다.\n",
      "건물주의 운전기사로 시작해 세를 얻어 희망을 품고 시작한 막국수 집은 인상이 서글서글한 부자의 웃음과 열의로 그나마 장사가 되는 듯 했다.\n",
      "그러나 이곳은 팔당상수원 환경정비구역으로 남양주시와 의정부지검이 지난해 부터 단속을 벌여 음식점을 운영하던 7명이 구속됐다.\n",
      "황씨가 운영하던 막국수 집도 단속을 피할 수 없었다. 지난해 12월 단속을 더이상 견딜 수 없었던 이들은 결국 음식점 문을 닫았다.\n",
      "문제는 수입은 없는데 검찰이 내린 벌금 3000만원과 남양주시의 이행강제금 3690만원을 감당하기에는 너무나 힘에 부쳤다. 주변 가게에서 아르바이트를 해도 생활비는 커녕 벌금과 과태료도 낼 수 없었다.\n",
      "결국 승우씨는 주변 지인과 카드빚을 내 휴가철 관광객들을 대상으로 소시지와 커피 등을 판매하는 노점상을 하기로 했다. 교제하던 여자친구와는 결혼도 미뤘다.\n",
      "하지만 이마저도 한강유역환경청이 휴가철 수질을 오염시킬 우려가 있다며 지난달 집중단속을 하면서 승우씨의 노점상도 손해만 본 채 접게 됐다. 승우씨는 지인들 뿐 아니라 금융권에서도 신용불량자의 낙인이 찍힌 채 절망에 빠졌다.\n",
      "이런 가운데 환경청에서 일부 원주민들에 대해서는 음식점 운영을 할 수 있도록 제도를 개선한다는 소식이 전해지면서 한줄기 희망이 생기는 듯 했다. 승우씨는 다시 장사를 할 수도 있다는 생각에 문을 닫았던 음식점의 주방부터 청소를 시작했다.\n",
      "하지만 환경청이 주민들의 의견을 묵살하면서 이같은 희망도 오래가지 못했다. 승우씨는 청소를 위해 음식점을 찾았다가 이같은 소식을 접했다.\n",
      "\n",
      "음식점 앞에는 독촉장이 쌓여 있었고 결국 승우씨는 자신이 청소해 오던 주방에서 노점상에 걸어 둔 현수막에 목을 메 스스로 목숨을 끊었다.\n",
      "승우씨는 목을 메는 순간에도 수사에 대한 두려움을 견디지 못한 자신을 탓하며 아버지를 걱정했다. A4용지 2장짜리 분량에는 \"수사도 두려울 뿐더러 잘 산 것 하나 없는 아들이라 죄송합니다. 늘 건강하시고 행복을 잃지 마세요\"라고 썼다.\n",
      "지난달 31일 오후 취재진이 찾은 승우씨의 장례시장 곳곳에서는 울음소리가 끊이지 않았다.\n",
      "승우씨의 아버지는 \"사람이 살 수 있게 몰아 부쳐야지 정부가 갈 곳 없이 벼랑 끝까지 아들을 내몰아 끝내 죽음을 선택하게 했다\"며 흐느꼈다.\n",
      "그는 \"빚까지 져가며 살아보겠다고 노점상 하나 차렸는데 이마저도 단속 당한다는 두려움과 다시 장사를 할 수 있다는 희망마저 끊어진 상태에서 이곳저곳 독촉까지 아들이 견뎌야 하는 짐이 너무 컸다\"며 \"아버지의 수호신이 된다는 아들의 마지막 말은 견딜 수 없을 정도로 아프다\"고 더이상 말을 잇지 못했다.\n",
      "승우씨의 지인은 \"불법이라는 것은 인정하지만 그렇다면 정상적으로 신고를 하고 영업할 수 있도록 해야지 무조건 규제를 하고 이를 빌미로 단속을 하는 것을 반복하는 것은 원주민들을 죽이기 위한 반복된 악행\"이라며 \"살 수 있는 방법은 조금이라도 마련해 줘야 하는 것 아니냐\"고 한탄했다.\n",
      "한편 조안면 주민들은 1일 오전 상여집회를 열기로 했다.\n"
     ]
    }
   ],
   "source": [
    "print(daum.body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:07.969399Z",
     "start_time": "2020-08-09T22:04:07.873924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26살 황승우씨는 지난 30일 오전 경기 남양주시 조안면 막국수집 주방에서 목을 메 숨진 채 발견됐다.\n",
      "이곳은 아버지 황선남(65)씨와 지난 2015년 희망을 품고 문을 연 가게였다.\n",
      "황씨가 운영하던 막국수 집도 단속을 피할 수 없었다.\n",
      "하지만 이마저도 한강유역환경청이 휴가철 수질을 오염시킬 우려가 있다며 지난달 집중단속을 하면서 승우씨의 노점상도 손해만 본 채 접게 됐다.\n"
     ]
    }
   ],
   "source": [
    "print(daum.summary[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sktbrain-kobert 예시 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:08.095074Z",
     "start_time": "2020-08-09T22:04:07.972399Z"
    }
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:08.225995Z",
     "start_time": "2020-08-09T22:04:08.097068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tok_path = get_tokenizer()\n",
    "sp  = SentencepieceTokenizer(tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:08.340102Z",
     "start_time": "2020-08-09T22:04:08.228995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁\"',\n",
       " '벌',\n",
       " '금',\n",
       " '과',\n",
       " '▁단속',\n",
       " '▁걱정',\n",
       " '하던',\n",
       " '▁아들',\n",
       " ',',\n",
       " '▁장',\n",
       " '사',\n",
       " '▁준비',\n",
       " '하던',\n",
       " '▁현',\n",
       " '수',\n",
       " '막',\n",
       " '으로',\n",
       " '▁목',\n",
       " '▁메',\n",
       " '▁숨']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_body_token = sp(daum.body[0])\n",
    "example_body_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:08.451220Z",
     "start_time": "2020-08-09T22:04:08.344101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁26',\n",
       " '살',\n",
       " '▁황',\n",
       " '승',\n",
       " '우',\n",
       " '씨는',\n",
       " '▁지난',\n",
       " '▁30',\n",
       " '일',\n",
       " '▁오전',\n",
       " '▁경기',\n",
       " '▁남',\n",
       " '양',\n",
       " '주',\n",
       " '시',\n",
       " '▁조',\n",
       " '안',\n",
       " '면',\n",
       " '▁막',\n",
       " '국']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_summary_token = sp(daum.summary[0])\n",
    "example_summary_token[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떻게 단어를 id로 바꾸는지 모르겠음...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kobert_transformers 예시 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:08.578425Z",
     "start_time": "2020-08-09T22:04:08.454220Z"
    }
   },
   "outputs": [],
   "source": [
    "from kobert_transformers import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:10.436285Z",
     "start_time": "2020-08-09T22:04:08.581421Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:10.459263Z",
     "start_time": "2020-08-09T22:04:10.438276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁\"',\n",
       " '벌',\n",
       " '금',\n",
       " '과',\n",
       " '▁단속',\n",
       " '▁걱정',\n",
       " '하던',\n",
       " '▁아들',\n",
       " ',',\n",
       " '▁장',\n",
       " '사',\n",
       " '▁준비',\n",
       " '하던',\n",
       " '▁현',\n",
       " '수',\n",
       " '막',\n",
       " '으로',\n",
       " '▁목',\n",
       " '▁메',\n",
       " '▁숨']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_body_token = tokenizer.tokenize(daum.body[0])\n",
    "example_body_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:10.760664Z",
     "start_time": "2020-08-09T22:04:10.462263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁26',\n",
       " '살',\n",
       " '▁황',\n",
       " '승',\n",
       " '우',\n",
       " '씨는',\n",
       " '▁지난',\n",
       " '▁30',\n",
       " '일',\n",
       " '▁오전',\n",
       " '▁경기',\n",
       " '▁남',\n",
       " '양',\n",
       " '주',\n",
       " '시',\n",
       " '▁조',\n",
       " '안',\n",
       " '면',\n",
       " '▁막',\n",
       " '국']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_summary_token = tokenizer.tokenize(daum.summary[0])\n",
    "example_summary_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:10.979843Z",
     "start_time": "2020-08-09T22:04:10.766655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[518,\n",
       " 6332,\n",
       " 5550,\n",
       " 5468,\n",
       " 1590,\n",
       " 880,\n",
       " 7802,\n",
       " 3107,\n",
       " 46,\n",
       " 3954,\n",
       " 6493,\n",
       " 4249,\n",
       " 7802,\n",
       " 5049,\n",
       " 6629,\n",
       " 6149,\n",
       " 7078,\n",
       " 2068,\n",
       " 2016,\n",
       " 2919]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_body_token_id = tokenizer.convert_tokens_to_ids(example_body_token)\n",
    "example_body_token_id[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:11.077906Z",
     "start_time": "2020-08-09T22:04:10.982840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[584,\n",
       " 6519,\n",
       " 5149,\n",
       " 6703,\n",
       " 7005,\n",
       " 6787,\n",
       " 4304,\n",
       " 592,\n",
       " 7126,\n",
       " 3431,\n",
       " 956,\n",
       " 1409,\n",
       " 6853,\n",
       " 7276,\n",
       " 6705,\n",
       " 4162,\n",
       " 6812,\n",
       " 6198,\n",
       " 1927,\n",
       " 5503]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_summary_token_id = tokenizer.convert_tokens_to_ids(example_summary_token)\n",
    "example_summary_token_id[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sktbrain-kobert 예시 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T21:09:59.319343Z",
     "start_time": "2020-08-09T21:09:59.291360Z"
    }
   },
   "source": [
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T21:10:06.201707Z",
     "start_time": "2020-08-09T21:10:00.919977Z"
    }
   },
   "source": [
    "model, vocab  = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kobert_transformers 예시 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:11.176017Z",
     "start_time": "2020-08-09T22:04:11.080902Z"
    }
   },
   "outputs": [],
   "source": [
    "from kobert_transformers import get_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:17.750446Z",
     "start_time": "2020-08-09T22:04:11.180014Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_kobert_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:17.759439Z",
     "start_time": "2020-08-09T22:04:17.753444Z"
    }
   },
   "outputs": [],
   "source": [
    "example_body_tensor = torch.LongTensor([example_body_token_id])\n",
    "example_summary_tensor = torch.LongTensor([example_summary_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:17.901353Z",
     "start_time": "2020-08-09T22:04:17.767434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 883])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_body_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:18.270175Z",
     "start_time": "2020-08-09T22:04:17.907349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index out of range in self\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    body_sequence_output, body_pooled_output = model(example_body_tensor)\n",
    "except IndexError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding vector의 차원이 768이니까 input의 길이가 768보다 커서 index error가 뜨는것인가...?\n",
    "\n",
    "단어 개수가 768개보다 작은거만 input으로 넣을 수 있다는게 말이 안되지 않나...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:18.756872Z",
     "start_time": "2020-08-09T22:04:18.273174Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_sequence_output, summary_pooled_output = model(example_summary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:18.767869Z",
     "start_time": "2020-08-09T22:04:18.759871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 116])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_summary_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:04:18.921771Z",
     "start_time": "2020-08-09T22:04:18.770864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 116, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sequence_output.shape, summary_pooled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1개의 sample\n",
    "\n",
    "단어수가 116개\n",
    "\n",
    "embedding vector의 차원이 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
