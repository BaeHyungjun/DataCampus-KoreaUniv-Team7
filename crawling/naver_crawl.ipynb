{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버뉴스 크롤링\n",
    "최근 2년 분야별 상위랭킹 30 기사의 {게시날짜, 제목, 본문, 요약본, 링크} 스크래핑  \n",
    "news.db 데이터베이스 내 navernews 테이블에 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import request\n",
    "from requests.compat import urljoin, urlparse\n",
    "from requests.exceptions import HTTPError\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "\n",
    "def canfetch(url, agent='*', path='/'):\n",
    "    robot = RobotFileParser(urljoin(url, '/robots.txt'))\n",
    "    robot.read()\n",
    "    return robot.can_fetch(agent, urlparse(url)[2])\n",
    "    \n",
    "def download(url, params={}, headers={}, method='GET', limit=3):\n",
    "#     if canfetch(url) == False:\n",
    "#         print('[Error] ' + url)\n",
    "    try:\n",
    "        resp = request(method, url,\n",
    "               params=params if method=='GET' else {},\n",
    "               data=params if method=='POST' else {},\n",
    "               headers=headers)\n",
    "        resp.raise_for_status()\n",
    "    except HTTPError as e:\n",
    "        if limit > 0 and e.response.status_code >= 500:\n",
    "            print(limit)\n",
    "            time.sleep(random.random()*5) # => random\n",
    "            resp = download(url, params, headers, method, limit-1)\n",
    "        else:\n",
    "            print('[{}] '.format(e.response.status_code) + url)\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "            print(e.response.headers)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATESLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "\n",
    "start = datetime.strptime('20180801', '%Y%m%d') \n",
    "end = datetime.today()\n",
    "datelst = [] \n",
    "while start.strftime('%Y%m%d') != end.strftime('%Y%m%d'): \n",
    "    datelst.append(start.strftime('%Y%m%d')) \n",
    "    start += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datelst[100])\n",
    "len(datelst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20180801~20200829  \n",
    "총 728일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSERT TO DB\n",
    "using sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('news.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x291bd05ab90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.executescript('''\n",
    "    DROP TABLE IF EXISTS navernews;\n",
    "    CREATE TABLE navernews(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        title TEXT NOT NULL,\n",
    "        date TEXT,\n",
    "        body TEXT,\n",
    "        summary TEXT,\n",
    "        link TEXT NOT NULL\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.naver.com/main/ranking/popularDay.nhn'\n",
    "params = {\n",
    "            'rankingType': 'popular_day',\n",
    "        }\n",
    "headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in str_date_list:\n",
    "        print(i, j)\n",
    "     \n",
    "        params['sectionId'] = '10'+str(i)\n",
    "        params['date']=j\n",
    "\n",
    "        resp = download(url, params=params, headers=headers)\n",
    "        if resp.status_code!=200:\n",
    "            continue\n",
    "        dom = BeautifulSoup(resp.content, 'lxml')\n",
    "        \n",
    "        \n",
    "        #뉴스링크 수집\n",
    "        urlst = []\n",
    "        for _ in dom.find_all('div',{'class':'ranking_headline'}):\n",
    "            if _.a['href'] not in urlst:\n",
    "                urlst.append(_.a['href'])\n",
    "        \n",
    "        for _ in urlst:\n",
    "            newslink = urljoin(url, _)\n",
    "            resp = download(newslink, headers=headers)\n",
    "            if resp.status_code!=200:\n",
    "                continue\n",
    "            dom = BeautifulSoup(resp.content, 'html.parser')\n",
    "            \n",
    "            #if there's summary button\n",
    "            if dom.find_all('a',{'class':'media_end_head_autosummary_button _toggle_btn nclicks(sum_summary)'}) != []:\n",
    "                ###제목###\n",
    "                title = dom.find('h3', {'id':'articleTitle'}).text.strip()\n",
    "                \n",
    "                ###기사작성일###\n",
    "                date = dom.find_all('span', {'class':'t11'})[0].text.strip()\n",
    "                \n",
    "                ###본문###\n",
    "                body = dom.find_all('div',{'id':'articleBodyContents'})[0].text.replace(\n",
    "                    '\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\\n\\n','').replace(\n",
    "                    '<br/>','').strip()\n",
    "\n",
    "                if re.search(\"▶\", body):\n",
    "                    body = body[:re.search(\"▶\", body).start()]\n",
    "\n",
    "                \n",
    "                ###요약###\n",
    "                parsed = (urlparse(newslink)).query.split('&')\n",
    "                oid = parsed[1]\n",
    "                aid = parsed[2]\n",
    "\n",
    "                oidno = re.search(re.compile(r'[^oid=]{3}'), oid).group(0)\n",
    "                aidno = re.search(re.compile(r'[^aid=]{10}'), aid).group(0)\n",
    "                \n",
    "                sumurl = 'https://tts.news.naver.com/article/'+oidno+'/'+aidno+'/summary'\n",
    "                sumresp = download(sumurl)\n",
    "                if sumresp.status_code!=200:\n",
    "                    continue\n",
    "                    \n",
    "                json = sumresp.json()\n",
    "                \n",
    "                summary = json['summary'].replace('<br/>','')\n",
    "                \n",
    "                \n",
    "                ###INSERT TO DB###\n",
    "                cur.execute('INSERT INTO navernews VALUES(NULL,?,?,?,?,?)',[title,date,body,summary,newslink])\n",
    "                conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
