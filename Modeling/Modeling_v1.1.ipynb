{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from kobert_transformers import get_kobert_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kobert_transformers import get_tokenizer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True) \n",
    "#코드 실행 전에 추가해주면 연산을 할때 어떤 장치에 할당 되었는지 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_token_id_padding.pkl', 'rb') as file:\n",
    "    train_X = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_kobert_model = get_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kobert_convert(integer_encoding, kobert_model):\n",
    "  '''정수 인코딩된 자료를 pytorch kobert 모델 통과해서 tensorflow의 tensor로 변환'''\n",
    "  return tf.convert_to_tensor(kobert_model(torch.LongTensor(integer_encoding))[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_normalized.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>body_morphs</th>\n",
       "      <th>summary_morphs</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이총리 \"폭염, 특별재난 준해…전기요금 제한적 특별배려 검토\"</td>\n",
       "      <td>2018.07.31. 오전 11:53</td>\n",
       "      <td>국무회의 주재···체계적 폭염대책 주문\"최저임금 명암···변화 수용하되 진통 최소화...</td>\n",
       "      <td>이낙연 국무총리는 31일 계속되는 폭염으로 전기요금 부담에 대한 우려가 커지고 있는...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[국무회의, 주재···체계적, 폭염대책, 주문, 최저임금, 명암···변화, 수용, ...</td>\n",
       "      <td>[이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려, 는, 관...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>김성태 \"盧 탄핵때도 기무사 대응문건 의혹…즉시 제출하라\"</td>\n",
       "      <td>2018.07.31. 오전 10:25</td>\n",
       "      <td>\"대통령, 여름휴가 때 노동자·소상공인 생각하길\"김성태 자유한국당 원내대표. = 김...</td>\n",
       "      <td>김성태 자유한국당 원내대표는 31일 \"지난 2004년 노무현 전 대통령 탄핵 당시 ...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[대통령, 여름휴가, 노동자·소상공, 생각하길\"김성태, 자유한국당, 원내대표, =,...</td>\n",
       "      <td>[김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄핵, 당시...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>합참, 北 ICBM 제작 정황 보도에 \"면밀히 추적·감시중\"</td>\n",
       "      <td>2018.07.31. 오전 11:29</td>\n",
       "      <td>노재천 공보실장 \"공식확인 부적절···한미간 공조\"워싱턴포스트 \"액화연료 사용 IC...</td>\n",
       "      <td>합동참모본부는 31일 북한이 대륙간탄도미사일을 만들고 있는 정황을 포착했다는 보도와...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[노재천, 공보실장, 공식확인, 부적절···한미간, 공조\"워싱턴포스트, 액화연료, ...</td>\n",
       "      <td>[합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포착, 었다...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>기무사 \"盧 대통령 탄핵 당시 계엄검토 문건 작성 안해\"</td>\n",
       "      <td>2018.07.31. 오후 2:43</td>\n",
       "      <td>김성태 의원 주장에 반박···지난 정부에서도 관련 내용 확인 국방부 특별수사단이 계...</td>\n",
       "      <td>국군기무사령부는 31일 노무현 전 대통령 탄핵 당시 계엄령 문건을 작성했다는 김성태...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[김성태, 의원, 주장, 반박···지난, 정부, 에서도, 관련, 내용, 확인, 국방...</td>\n",
       "      <td>[국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건, 작성, ...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>'종전문제 다룰까' 北, 이례적 회담 제의 이어 전향적 태도 보여</td>\n",
       "      <td>2018.07.31. 오후 12:55</td>\n",
       "      <td>안익산 대표 \" 흔들어 종전선언? 보도, 그럴 수 있다\" 이해 안익산 북측 수석대표...</td>\n",
       "      <td>북한이 이례적으로 남북 장성급 군사회담을 먼저 제의한데 이어 회담에서 전향적인 태도...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[안익산, 대표, 흔들, 종전선언, ?, 보도, 이해, 안익산, 북측, 수석대표, ...</td>\n",
       "      <td>[북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, 회담, 전...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                 title                  date  \\\n",
       "0   1    이총리 \"폭염, 특별재난 준해…전기요금 제한적 특별배려 검토\"  2018.07.31. 오전 11:53   \n",
       "1   2      김성태 \"盧 탄핵때도 기무사 대응문건 의혹…즉시 제출하라\"  2018.07.31. 오전 10:25   \n",
       "2   3     합참, 北 ICBM 제작 정황 보도에 \"면밀히 추적·감시중\"  2018.07.31. 오전 11:29   \n",
       "3   4       기무사 \"盧 대통령 탄핵 당시 계엄검토 문건 작성 안해\"   2018.07.31. 오후 2:43   \n",
       "4   5  '종전문제 다룰까' 北, 이례적 회담 제의 이어 전향적 태도 보여  2018.07.31. 오후 12:55   \n",
       "\n",
       "                                                body  \\\n",
       "0  국무회의 주재···체계적 폭염대책 주문\"최저임금 명암···변화 수용하되 진통 최소화...   \n",
       "1  \"대통령, 여름휴가 때 노동자·소상공인 생각하길\"김성태 자유한국당 원내대표. = 김...   \n",
       "2  노재천 공보실장 \"공식확인 부적절···한미간 공조\"워싱턴포스트 \"액화연료 사용 IC...   \n",
       "3  김성태 의원 주장에 반박···지난 정부에서도 관련 내용 확인 국방부 특별수사단이 계...   \n",
       "4  안익산 대표 \" 흔들어 종전선언? 보도, 그럴 수 있다\" 이해 안익산 북측 수석대표...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  이낙연 국무총리는 31일 계속되는 폭염으로 전기요금 부담에 대한 우려가 커지고 있는...   \n",
       "1  김성태 자유한국당 원내대표는 31일 \"지난 2004년 노무현 전 대통령 탄핵 당시 ...   \n",
       "2  합동참모본부는 31일 북한이 대륙간탄도미사일을 만들고 있는 정황을 포착했다는 보도와...   \n",
       "3  국군기무사령부는 31일 노무현 전 대통령 탄핵 당시 계엄령 문건을 작성했다는 김성태...   \n",
       "4  북한이 이례적으로 남북 장성급 군사회담을 먼저 제의한데 이어 회담에서 전향적인 태도...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "1  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "2  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "3  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "4  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "\n",
       "                                         body_morphs  \\\n",
       "0  [국무회의, 주재···체계적, 폭염대책, 주문, 최저임금, 명암···변화, 수용, ...   \n",
       "1  [대통령, 여름휴가, 노동자·소상공, 생각하길\"김성태, 자유한국당, 원내대표, =,...   \n",
       "2  [노재천, 공보실장, 공식확인, 부적절···한미간, 공조\"워싱턴포스트, 액화연료, ...   \n",
       "3  [김성태, 의원, 주장, 반박···지난, 정부, 에서도, 관련, 내용, 확인, 국방...   \n",
       "4  [안익산, 대표, 흔들, 종전선언, ?, 보도, 이해, 안익산, 북측, 수석대표, ...   \n",
       "\n",
       "                                      summary_morphs   site  \n",
       "0  [이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려, 는, 관...  naver  \n",
       "1  [김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄핵, 당시...  naver  \n",
       "2  [합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포착, 었다...  naver  \n",
       "3  [국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건, 작성, ...  naver  \n",
       "4  [북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, 회담, 전...  naver  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리가없어...5만개로 줄여보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smorphs = data.summary_morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smorphs = smorphs.apply(lambda x : ['sos']+x+['eos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [sos, 이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려,...\n",
       "1    [sos, 김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄...\n",
       "2    [sos, 합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포...\n",
       "3    [sos, 국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건,...\n",
       "4    [sos, 북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, ...\n",
       "Name: summary_morphs, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smorphs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "m = 200\n",
    "cnt= 0\n",
    "for n,_ in enumerate(smorphs):\n",
    "    if len(_)>m:\n",
    "        l.append(n)\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m #maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[289, 384, 1086, 1194, 1355]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarytok = []\n",
    "for _ in smorphs:\n",
    "    el_id = tok.convert_tokens_to_ids(_)\n",
    "    summarytok.append(el_id[:200])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = set()\n",
    "for lst in summarytok:\n",
    "    for _ in lst:\n",
    "        if _ not in hi:\n",
    "            hi.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hi) #max가 8001이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi2 = set()\n",
    "for lst in train_x:\n",
    "    for _ in lst:\n",
    "        if _ not in hi:\n",
    "            hi2.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hi2) #본문내 max는 7999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sos=2, eos=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarytok = []\n",
    "for _ in smorphs:\n",
    "    el_id = tok.convert_tokens_to_ids(_)\n",
    "    el_id[0] = 2 #sos\n",
    "    el_id[-1] = 3 #eos\n",
    "    if(len(el_id)<200):\n",
    "        new = el_id+[0]*(200-len(el_id))\n",
    "    elif(len(el_id)>200):\n",
    "        new = el_id[:200]\n",
    "        new[-1] = 3 #eos\n",
    "    summarytok.append(new)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[2, 0, 0, 0, 147, 0, 0, 5821, 0, 0, 0, 0, 0, 7782, 8, 5439, 0, 7782, 6888, 5585, 0, 5760, 0, 6556, 0, 5511, 6903, 0, 0, 0, 0, 6903, 0, 0, 7096, 0, 6210, 0, 0, 0, 7157, 7096, 0, 6157, 0, 5760, 0, 6544, 5886, 0, 0, 7088, 0, 0, 6888, 54, 5585, 0, 0, 5760, 8, 5725, 7207, 5821, 0, 0, 0, 5516, 0, 0, 0, 6903, 0, 7088, 0, 7782, 0, 0, 7096, 0, 5330, 5439, 0, 8, 0, 0, 6484, 0, 0, 5859, 5507, 0, 0, 6903, 0, 6855, 7782, 0, 8, 5439, 0, 7782, 6888, 54, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(summarytok[1]))\n",
    "print(summarytok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 6634, 7096, 0, 0, 0, 0, 0, 0, 0, 0, 7095, 0, 0, 5477, 0, 0, 15, 0, 0, 0, 7088, 7945, 7782, 0, 6888, 0, 7086, 0, 0, 0, 7096, 5788, 0, 15, 6005, 0, 7095, 0, 0, 6896, 0, 7095, 0, 7096, 0, 0, 0, 5886, 0, 0, 7088, 0, 7096, 7295, 0, 6116, 0, 8, 0, 5886, 0, 0, 6896, 0, 0, 7289, 6896, 0, 0, 0, 7096, 0, 5886, 0, 6896, 0, 7788, 0, 6421, 7157, 0, 0, 6645, 7088, 0, 6855, 0, 7096, 0, 0, 6116, 7945, 7782, 0, 7088, 0, 7788, 8, 5439, 6300, 7782, 6888, 54, 0, 7086, 8, 0, 6366, 0, 0, 0, 7086, 6867, 6896, 5454, 5886, 0, 0, 7096, 0, 15, 0, 6271, 0, 0, 15, 7096, 0, 15, 7903, 0, 5477, 0, 15, 7096, 6889, 0, 0, 5760, 0, 0, 0, 6116, 0, 6896, 7012, 7782, 6855, 15, 6258, 0, 0, 15, 0, 6016, 0, 7078, 0, 6356, 0, 6116, 0, 7782, 6886, 46, 6165, 7096, 0, 5886, 0, 334, 6116, 0, 7782, 6855, 0, 7088, 0, 7782, 6892, 46, 0, 7012, 0, 0, 5886, 0, 0, 7096, 5561, 3]\n"
     ]
    }
   ],
   "source": [
    "print(len(summarytok[289]))\n",
    "print(summarytok[289])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = set()\n",
    "for lst in summarytok:\n",
    "    for _ in lst:\n",
    "        if _ not in hi:\n",
    "            hi.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = np.array(summarytok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEGNTH = 512 #for padding\n",
    "NUM_WORDS = 2064 #본문 기사 내 가장 많이 사용된 3000단어?(or 전체 단어수로 할지 미정)\n",
    "VECTOR_SIZE = 768\n",
    "MAX_SUMMARIZATION_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "for n,_ in enumerate(hi):\n",
    "    mapping[n] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 2, 2: 3, 3: 5, 4: 6, 5: 8, 6: 11, 7: 15, 8: 17, 9: 41, 10: 42, 11: 45, 12: 46, 13: 47, 14: 49, 15: 50, 16: 53, 17: 54, 18: 55, 19: 56, 20: 57, 21: 59, 22: 60, 23: 63, 24: 65, 25: 68, 26: 71, 27: 73, 28: 75, 29: 77, 30: 79, 31: 81, 32: 82, 33: 83, 34: 85, 35: 86, 36: 87, 37: 88, 38: 89, 39: 90, 40: 91, 41: 93, 42: 97, 43: 101, 44: 104, 45: 105, 46: 106, 47: 107, 48: 108, 49: 109, 50: 110, 51: 111, 52: 112, 53: 113, 54: 114, 55: 115, 56: 116, 57: 119, 58: 122, 59: 124, 60: 127, 61: 128, 62: 129, 63: 130, 64: 131, 65: 132, 66: 133, 67: 134, 68: 135, 69: 136, 70: 137, 71: 138, 72: 139, 73: 140, 74: 141, 75: 142, 76: 144, 77: 145, 78: 146, 79: 147, 80: 148, 81: 149, 82: 150, 83: 151, 84: 152, 85: 153, 86: 154, 87: 155, 88: 157, 89: 160, 90: 161, 91: 162, 92: 163, 93: 164, 94: 165, 95: 166, 96: 167, 97: 168, 98: 169, 99: 170, 100: 171, 101: 172, 102: 175, 103: 176, 104: 177, 105: 178, 106: 179, 107: 180, 108: 181, 109: 182, 110: 183, 111: 184, 112: 185, 113: 186, 114: 187, 115: 188, 116: 190, 117: 191, 118: 192, 119: 193, 120: 194, 121: 195, 122: 196, 123: 197, 124: 198, 125: 199, 126: 200, 127: 201, 128: 202, 129: 205, 130: 207, 131: 208, 132: 209, 133: 210, 134: 211, 135: 212, 136: 213, 137: 214, 138: 215, 139: 216, 140: 217, 141: 218, 142: 219, 143: 222, 144: 223, 145: 224, 146: 225, 147: 226, 148: 227, 149: 228, 150: 229, 151: 230, 152: 231, 153: 232, 154: 233, 155: 234, 156: 237, 157: 238, 158: 239, 159: 240, 160: 241, 161: 242, 162: 243, 163: 244, 164: 245, 165: 246, 166: 247, 167: 248, 168: 249, 169: 253, 170: 254, 171: 257, 172: 258, 173: 259, 174: 264, 175: 266, 176: 267, 177: 268, 178: 269, 179: 270, 180: 271, 181: 274, 182: 275, 183: 276, 184: 277, 185: 278, 186: 279, 187: 280, 188: 282, 189: 283, 190: 284, 191: 285, 192: 286, 193: 287, 194: 288, 195: 289, 196: 290, 197: 291, 198: 292, 199: 293, 200: 294, 201: 295, 202: 296, 203: 298, 204: 299, 205: 300, 206: 301, 207: 303, 208: 304, 209: 305, 210: 306, 211: 307, 212: 308, 213: 309, 214: 310, 215: 311, 216: 312, 217: 313, 218: 315, 219: 316, 220: 317, 221: 318, 222: 319, 223: 320, 224: 321, 225: 322, 226: 325, 227: 326, 228: 328, 229: 329, 230: 331, 231: 332, 232: 333, 233: 334, 234: 335, 235: 336, 236: 337, 237: 338, 238: 339, 239: 340, 240: 341, 241: 342, 242: 343, 243: 344, 244: 345, 245: 346, 246: 347, 247: 348, 248: 349, 249: 351, 250: 354, 251: 355, 252: 356, 253: 357, 254: 358, 255: 359, 256: 360, 257: 361, 258: 363, 259: 366, 260: 367, 261: 380, 262: 382, 263: 388, 264: 389, 265: 399, 266: 401, 267: 404, 268: 405, 269: 409, 270: 412, 271: 413, 272: 417, 273: 418, 274: 423, 275: 429, 276: 432, 277: 435, 278: 440, 279: 442, 280: 446, 281: 457, 282: 463, 283: 478, 284: 5330, 285: 5331, 286: 5332, 287: 5333, 288: 5334, 289: 5335, 290: 5336, 291: 5337, 292: 5340, 293: 5341, 294: 5342, 295: 5343, 296: 5345, 297: 5346, 298: 5347, 299: 5350, 300: 5351, 301: 5353, 302: 5354, 303: 5356, 304: 5357, 305: 5358, 306: 5359, 307: 5362, 308: 5363, 309: 5364, 310: 5365, 311: 5366, 312: 5368, 313: 5369, 314: 5370, 315: 5372, 316: 5374, 317: 5377, 318: 5378, 319: 5379, 320: 5380, 321: 5381, 322: 5382, 323: 5384, 324: 5385, 325: 5386, 326: 5388, 327: 5389, 328: 5390, 329: 5391, 330: 5392, 331: 5393, 332: 5394, 333: 5395, 334: 5396, 335: 5397, 336: 5398, 337: 5399, 338: 5400, 339: 5401, 340: 5403, 341: 5406, 342: 5408, 343: 5409, 344: 5410, 345: 5411, 346: 5412, 347: 5413, 348: 5414, 349: 5415, 350: 5416, 351: 5417, 352: 5418, 353: 5419, 354: 5420, 355: 5424, 356: 5425, 357: 5427, 358: 5428, 359: 5429, 360: 5430, 361: 5431, 362: 5432, 363: 5434, 364: 5435, 365: 5436, 366: 5437, 367: 5438, 368: 5439, 369: 5440, 370: 5441, 371: 5442, 372: 5443, 373: 5444, 374: 5445, 375: 5446, 376: 5448, 377: 5449, 378: 5450, 379: 5451, 380: 5452, 381: 5453, 382: 5454, 383: 5455, 384: 5456, 385: 5457, 386: 5458, 387: 5459, 388: 5460, 389: 5461, 390: 5462, 391: 5463, 392: 5464, 393: 5465, 394: 5466, 395: 5467, 396: 5468, 397: 5469, 398: 5471, 399: 5472, 400: 5473, 401: 5474, 402: 5475, 403: 5476, 404: 5477, 405: 5478, 406: 5479, 407: 5480, 408: 5481, 409: 5482, 410: 5483, 411: 5485, 412: 5486, 413: 5488, 414: 5489, 415: 5490, 416: 5491, 417: 5492, 418: 5493, 419: 5494, 420: 5495, 421: 5496, 422: 5497, 423: 5499, 424: 5501, 425: 5502, 426: 5503, 427: 5504, 428: 5505, 429: 5506, 430: 5507, 431: 5508, 432: 5509, 433: 5510, 434: 5511, 435: 5512, 436: 5513, 437: 5515, 438: 5516, 439: 5517, 440: 5518, 441: 5519, 442: 5520, 443: 5521, 444: 5522, 445: 5524, 446: 5528, 447: 5529, 448: 5533, 449: 5534, 450: 5535, 451: 5536, 452: 5537, 453: 5538, 454: 5539, 455: 5540, 456: 5542, 457: 5543, 458: 5545, 459: 5546, 460: 5547, 461: 5548, 462: 5549, 463: 5550, 464: 5551, 465: 5552, 466: 5553, 467: 5554, 468: 5555, 469: 5556, 470: 5558, 471: 5559, 472: 5561, 473: 5563, 474: 5564, 475: 5565, 476: 5566, 477: 5567, 478: 5569, 479: 5570, 480: 5571, 481: 5572, 482: 5574, 483: 5575, 484: 5576, 485: 5577, 486: 5578, 487: 5580, 488: 5581, 489: 5582, 490: 5583, 491: 5584, 492: 5585, 493: 5586, 494: 5587, 495: 5590, 496: 5591, 497: 5592, 498: 5593, 499: 5594, 500: 5596, 501: 5598, 502: 5600, 503: 5602, 504: 5605, 505: 5607, 506: 5611, 507: 5612, 508: 5615, 509: 5616, 510: 5617, 511: 5619, 512: 5621, 513: 5622, 514: 5624, 515: 5625, 516: 5626, 517: 5627, 518: 5628, 519: 5630, 520: 5631, 521: 5632, 522: 5636, 523: 5637, 524: 5640, 525: 5642, 526: 5643, 527: 5644, 528: 5645, 529: 5648, 530: 5649, 531: 5650, 532: 5655, 533: 5658, 534: 5659, 535: 5660, 536: 5661, 537: 5662, 538: 5663, 539: 5664, 540: 5665, 541: 5666, 542: 5667, 543: 5668, 544: 5669, 545: 5670, 546: 5673, 547: 5674, 548: 5675, 549: 5677, 550: 5678, 551: 5689, 552: 5690, 553: 5691, 554: 5693, 555: 5694, 556: 5696, 557: 5697, 558: 5698, 559: 5701, 560: 5702, 561: 5704, 562: 5708, 563: 5712, 564: 5724, 565: 5725, 566: 5726, 567: 5727, 568: 5729, 569: 5730, 570: 5731, 571: 5732, 572: 5733, 573: 5734, 574: 5735, 575: 5736, 576: 5737, 577: 5739, 578: 5741, 579: 5743, 580: 5745, 581: 5748, 582: 5751, 583: 5753, 584: 5754, 585: 5755, 586: 5758, 587: 5760, 588: 5761, 589: 5762, 590: 5763, 591: 5765, 592: 5766, 593: 5767, 594: 5768, 595: 5770, 596: 5771, 597: 5772, 598: 5773, 599: 5774, 600: 5775, 601: 5777, 602: 5778, 603: 5781, 604: 5782, 605: 5783, 606: 5784, 607: 5785, 608: 5787, 609: 5788, 610: 5789, 611: 5790, 612: 5791, 613: 5792, 614: 5793, 615: 5794, 616: 5795, 617: 5796, 618: 5797, 619: 5798, 620: 5799, 621: 5800, 622: 5801, 623: 5802, 624: 5803, 625: 5804, 626: 5805, 627: 5806, 628: 5807, 629: 5808, 630: 5809, 631: 5810, 632: 5811, 633: 5812, 634: 5814, 635: 5815, 636: 5816, 637: 5818, 638: 5819, 639: 5820, 640: 5821, 641: 5822, 642: 5823, 643: 5824, 644: 5825, 645: 5826, 646: 5827, 647: 5828, 648: 5829, 649: 5830, 650: 5833, 651: 5837, 652: 5838, 653: 5839, 654: 5840, 655: 5841, 656: 5842, 657: 5843, 658: 5845, 659: 5846, 660: 5848, 661: 5849, 662: 5850, 663: 5855, 664: 5859, 665: 5860, 666: 5861, 667: 5862, 668: 5863, 669: 5864, 670: 5865, 671: 5866, 672: 5867, 673: 5868, 674: 5870, 675: 5872, 676: 5873, 677: 5874, 678: 5875, 679: 5880, 680: 5886, 681: 5890, 682: 5893, 683: 5900, 684: 5907, 685: 5908, 686: 5910, 687: 5913, 688: 5916, 689: 5917, 690: 5918, 691: 5920, 692: 5922, 693: 5923, 694: 5924, 695: 5926, 696: 5927, 697: 5928, 698: 5929, 699: 5930, 700: 5931, 701: 5940, 702: 5943, 703: 5944, 704: 5945, 705: 5946, 706: 5947, 707: 5948, 708: 5949, 709: 5950, 710: 5951, 711: 5952, 712: 5953, 713: 5954, 714: 5957, 715: 5959, 716: 5961, 717: 5962, 718: 5963, 719: 5964, 720: 5965, 721: 5970, 722: 5972, 723: 5976, 724: 5980, 725: 5981, 726: 5983, 727: 5985, 728: 5986, 729: 5988, 730: 5991, 731: 5994, 732: 5995, 733: 5996, 734: 5997, 735: 5998, 736: 6001, 737: 6003, 738: 6004, 739: 6005, 740: 6006, 741: 6007, 742: 6008, 743: 6009, 744: 6010, 745: 6011, 746: 6012, 747: 6013, 748: 6014, 749: 6015, 750: 6016, 751: 6018, 752: 6019, 753: 6022, 754: 6023, 755: 6026, 756: 6028, 757: 6029, 758: 6030, 759: 6033, 760: 6035, 761: 6037, 762: 6038, 763: 6040, 764: 6041, 765: 6044, 766: 6050, 767: 6051, 768: 6052, 769: 6055, 770: 6059, 771: 6060, 772: 6061, 773: 6062, 774: 6063, 775: 6069, 776: 6079, 777: 6080, 778: 6081, 779: 6082, 780: 6083, 781: 6084, 782: 6085, 783: 6086, 784: 6087, 785: 6090, 786: 6091, 787: 6094, 788: 6095, 789: 6097, 790: 6099, 791: 6100, 792: 6104, 793: 6107, 794: 6109, 795: 6113, 796: 6116, 797: 6122, 798: 6123, 799: 6124, 800: 6126, 801: 6127, 802: 6128, 803: 6130, 804: 6131, 805: 6132, 806: 6133, 807: 6134, 808: 6135, 809: 6136, 810: 6137, 811: 6139, 812: 6140, 813: 6141, 814: 6142, 815: 6143, 816: 6144, 817: 6146, 818: 6147, 819: 6148, 820: 6149, 821: 6150, 822: 6152, 823: 6153, 824: 6156, 825: 6157, 826: 6158, 827: 6160, 828: 6161, 829: 6162, 830: 6164, 831: 6165, 832: 6166, 833: 6167, 834: 6168, 835: 6169, 836: 6170, 837: 6171, 838: 6172, 839: 6173, 840: 6175, 841: 6176, 842: 6178, 843: 6180, 844: 6181, 845: 6182, 846: 6183, 847: 6184, 848: 6186, 849: 6188, 850: 6189, 851: 6190, 852: 6191, 853: 6197, 854: 6198, 855: 6199, 856: 6201, 857: 6202, 858: 6204, 859: 6210, 860: 6212, 861: 6213, 862: 6214, 863: 6215, 864: 6216, 865: 6217, 866: 6218, 867: 6219, 868: 6221, 869: 6222, 870: 6224, 871: 6227, 872: 6228, 873: 6230, 874: 6231, 875: 6232, 876: 6233, 877: 6234, 878: 6236, 879: 6237, 880: 6238, 881: 6239, 882: 6240, 883: 6241, 884: 6243, 885: 6247, 886: 6248, 887: 6249, 888: 6250, 889: 6252, 890: 6255, 891: 6256, 892: 6257, 893: 6258, 894: 6259, 895: 6260, 896: 6261, 897: 6262, 898: 6263, 899: 6264, 900: 6265, 901: 6266, 902: 6267, 903: 6268, 904: 6270, 905: 6271, 906: 6272, 907: 6273, 908: 6274, 909: 6275, 910: 6276, 911: 6278, 912: 6279, 913: 6280, 914: 6281, 915: 6282, 916: 6283, 917: 6284, 918: 6285, 919: 6286, 920: 6287, 921: 6288, 922: 6295, 923: 6296, 924: 6297, 925: 6298, 926: 6299, 927: 6300, 928: 6301, 929: 6302, 930: 6303, 931: 6304, 932: 6305, 933: 6306, 934: 6307, 935: 6308, 936: 6309, 937: 6310, 938: 6311, 939: 6312, 940: 6313, 941: 6314, 942: 6315, 943: 6316, 944: 6317, 945: 6319, 946: 6322, 947: 6323, 948: 6324, 949: 6326, 950: 6328, 951: 6330, 952: 6332, 953: 6333, 954: 6334, 955: 6335, 956: 6336, 957: 6338, 958: 6339, 959: 6341, 960: 6343, 961: 6344, 962: 6345, 963: 6347, 964: 6348, 965: 6349, 966: 6350, 967: 6353, 968: 6354, 969: 6355, 970: 6356, 971: 6357, 972: 6361, 973: 6362, 974: 6363, 975: 6364, 976: 6365, 977: 6366, 978: 6367, 979: 6371, 980: 6372, 981: 6374, 982: 6375, 983: 6376, 984: 6377, 985: 6378, 986: 6379, 987: 6380, 988: 6381, 989: 6382, 990: 6383, 991: 6384, 992: 6385, 993: 6386, 994: 6387, 995: 6388, 996: 6389, 997: 6391, 998: 6392, 999: 6397, 1000: 6398, 1001: 6399, 1002: 6401, 1003: 6402, 1004: 6404, 1005: 6405, 1006: 6406, 1007: 6407, 1008: 6408, 1009: 6409, 1010: 6410, 1011: 6411, 1012: 6412, 1013: 6413, 1014: 6414, 1015: 6415, 1016: 6416, 1017: 6418, 1018: 6421, 1019: 6422, 1020: 6424, 1021: 6425, 1022: 6426, 1023: 6427, 1024: 6428, 1025: 6429, 1026: 6430, 1027: 6431, 1028: 6433, 1029: 6434, 1030: 6435, 1031: 6439, 1032: 6440, 1033: 6441, 1034: 6444, 1035: 6445, 1036: 6446, 1037: 6447, 1038: 6448, 1039: 6449, 1040: 6450, 1041: 6451, 1042: 6452, 1043: 6454, 1044: 6455, 1045: 6456, 1046: 6457, 1047: 6458, 1048: 6460, 1049: 6461, 1050: 6463, 1051: 6464, 1052: 6465, 1053: 6467, 1054: 6470, 1055: 6473, 1056: 6474, 1057: 6476, 1058: 6477, 1059: 6480, 1060: 6484, 1061: 6485, 1062: 6486, 1063: 6487, 1064: 6492, 1065: 6493, 1066: 6494, 1067: 6495, 1068: 6496, 1069: 6498, 1070: 6499, 1071: 6501, 1072: 6502, 1073: 6503, 1074: 6504, 1075: 6505, 1076: 6506, 1077: 6508, 1078: 6509, 1079: 6510, 1080: 6511, 1081: 6513, 1082: 6514, 1083: 6515, 1084: 6516, 1085: 6517, 1086: 6518, 1087: 6519, 1088: 6520, 1089: 6521, 1090: 6522, 1091: 6523, 1092: 6524, 1093: 6527, 1094: 6528, 1095: 6529, 1096: 6530, 1097: 6532, 1098: 6533, 1099: 6534, 1100: 6536, 1101: 6537, 1102: 6538, 1103: 6541, 1104: 6542, 1105: 6543, 1106: 6544, 1107: 6545, 1108: 6546, 1109: 6549, 1110: 6550, 1111: 6552, 1112: 6553, 1113: 6554, 1114: 6555, 1115: 6556, 1116: 6557, 1117: 6558, 1118: 6559, 1119: 6560, 1120: 6561, 1121: 6562, 1122: 6566, 1123: 6567, 1124: 6568, 1125: 6569, 1126: 6573, 1127: 6574, 1128: 6578, 1129: 6579, 1130: 6580, 1131: 6581, 1132: 6582, 1133: 6583, 1134: 6584, 1135: 6587, 1136: 6588, 1137: 6589, 1138: 6592, 1139: 6593, 1140: 6596, 1141: 6597, 1142: 6599, 1143: 6602, 1144: 6605, 1145: 6606, 1146: 6607, 1147: 6608, 1148: 6609, 1149: 6610, 1150: 6611, 1151: 6612, 1152: 6614, 1153: 6615, 1154: 6616, 1155: 6617, 1156: 6618, 1157: 6619, 1158: 6620, 1159: 6621, 1160: 6622, 1161: 6624, 1162: 6625, 1163: 6626, 1164: 6627, 1165: 6628, 1166: 6629, 1167: 6630, 1168: 6632, 1169: 6634, 1170: 6635, 1171: 6636, 1172: 6637, 1173: 6638, 1174: 6639, 1175: 6640, 1176: 6641, 1177: 6643, 1178: 6644, 1179: 6645, 1180: 6646, 1181: 6650, 1182: 6651, 1183: 6653, 1184: 6654, 1185: 6657, 1186: 6658, 1187: 6659, 1188: 6660, 1189: 6663, 1190: 6664, 1191: 6669, 1192: 6673, 1193: 6678, 1194: 6681, 1195: 6683, 1196: 6684, 1197: 6685, 1198: 6686, 1199: 6687, 1200: 6689, 1201: 6690, 1202: 6692, 1203: 6693, 1204: 6694, 1205: 6695, 1206: 6697, 1207: 6699, 1208: 6700, 1209: 6701, 1210: 6703, 1211: 6705, 1212: 6706, 1213: 6708, 1214: 6709, 1215: 6710, 1216: 6712, 1217: 6713, 1218: 6715, 1219: 6716, 1220: 6718, 1221: 6719, 1222: 6722, 1223: 6728, 1224: 6729, 1225: 6730, 1226: 6732, 1227: 6733, 1228: 6734, 1229: 6735, 1230: 6736, 1231: 6737, 1232: 6738, 1233: 6739, 1234: 6741, 1235: 6742, 1236: 6743, 1237: 6744, 1238: 6745, 1239: 6746, 1240: 6747, 1241: 6749, 1242: 6750, 1243: 6751, 1244: 6752, 1245: 6753, 1246: 6754, 1247: 6756, 1248: 6759, 1249: 6760, 1250: 6762, 1251: 6764, 1252: 6770, 1253: 6771, 1254: 6773, 1255: 6777, 1256: 6778, 1257: 6779, 1258: 6781, 1259: 6785, 1260: 6792, 1261: 6793, 1262: 6794, 1263: 6795, 1264: 6797, 1265: 6798, 1266: 6799, 1267: 6800, 1268: 6801, 1269: 6803, 1270: 6804, 1271: 6805, 1272: 6806, 1273: 6807, 1274: 6808, 1275: 6809, 1276: 6810, 1277: 6811, 1278: 6812, 1279: 6813, 1280: 6814, 1281: 6816, 1282: 6817, 1283: 6818, 1284: 6819, 1285: 6820, 1286: 6821, 1287: 6823, 1288: 6824, 1289: 6826, 1290: 6828, 1291: 6831, 1292: 6832, 1293: 6834, 1294: 6835, 1295: 6837, 1296: 6838, 1297: 6840, 1298: 6842, 1299: 6844, 1300: 6845, 1301: 6846, 1302: 6847, 1303: 6848, 1304: 6850, 1305: 6852, 1306: 6853, 1307: 6854, 1308: 6855, 1309: 6856, 1310: 6857, 1311: 6858, 1312: 6861, 1313: 6865, 1314: 6867, 1315: 6868, 1316: 6869, 1317: 6870, 1318: 6873, 1319: 6874, 1320: 6875, 1321: 6876, 1322: 6877, 1323: 6878, 1324: 6879, 1325: 6880, 1326: 6881, 1327: 6883, 1328: 6886, 1329: 6887, 1330: 6888, 1331: 6889, 1332: 6890, 1333: 6891, 1334: 6892, 1335: 6893, 1336: 6894, 1337: 6895, 1338: 6896, 1339: 6897, 1340: 6898, 1341: 6899, 1342: 6900, 1343: 6901, 1344: 6902, 1345: 6903, 1346: 6904, 1347: 6905, 1348: 6906, 1349: 6908, 1350: 6909, 1351: 6910, 1352: 6911, 1353: 6912, 1354: 6913, 1355: 6916, 1356: 6917, 1357: 6918, 1358: 6919, 1359: 6920, 1360: 6923, 1361: 6924, 1362: 6925, 1363: 6926, 1364: 6927, 1365: 6928, 1366: 6929, 1367: 6930, 1368: 6931, 1369: 6932, 1370: 6933, 1371: 6934, 1372: 6936, 1373: 6938, 1374: 6939, 1375: 6940, 1376: 6943, 1377: 6946, 1378: 6947, 1379: 6951, 1380: 6952, 1381: 6953, 1382: 6954, 1383: 6955, 1384: 6956, 1385: 6957, 1386: 6958, 1387: 6959, 1388: 6960, 1389: 6963, 1390: 6964, 1391: 6965, 1392: 6966, 1393: 6967, 1394: 6968, 1395: 6969, 1396: 6970, 1397: 6972, 1398: 6973, 1399: 6974, 1400: 6975, 1401: 6976, 1402: 6977, 1403: 6980, 1404: 6981, 1405: 6982, 1406: 6983, 1407: 6984, 1408: 6985, 1409: 6988, 1410: 6992, 1411: 6993, 1412: 6995, 1413: 6996, 1414: 6998, 1415: 6999, 1416: 7000, 1417: 7001, 1418: 7003, 1419: 7004, 1420: 7005, 1421: 7007, 1422: 7010, 1423: 7011, 1424: 7012, 1425: 7013, 1426: 7015, 1427: 7016, 1428: 7018, 1429: 7020, 1430: 7028, 1431: 7030, 1432: 7031, 1433: 7032, 1434: 7038, 1435: 7039, 1436: 7040, 1437: 7041, 1438: 7043, 1439: 7044, 1440: 7046, 1441: 7048, 1442: 7050, 1443: 7052, 1444: 7053, 1445: 7054, 1446: 7056, 1447: 7059, 1448: 7060, 1449: 7061, 1450: 7062, 1451: 7063, 1452: 7064, 1453: 7065, 1454: 7066, 1455: 7068, 1456: 7069, 1457: 7074, 1458: 7075, 1459: 7076, 1460: 7077, 1461: 7078, 1462: 7079, 1463: 7080, 1464: 7081, 1465: 7082, 1466: 7083, 1467: 7084, 1468: 7086, 1469: 7087, 1470: 7088, 1471: 7089, 1472: 7090, 1473: 7093, 1474: 7095, 1475: 7096, 1476: 7098, 1477: 7099, 1478: 7104, 1479: 7106, 1480: 7107, 1481: 7109, 1482: 7110, 1483: 7114, 1484: 7115, 1485: 7117, 1486: 7118, 1487: 7119, 1488: 7121, 1489: 7122, 1490: 7123, 1491: 7124, 1492: 7125, 1493: 7126, 1494: 7127, 1495: 7129, 1496: 7130, 1497: 7131, 1498: 7134, 1499: 7135, 1500: 7136, 1501: 7138, 1502: 7140, 1503: 7141, 1504: 7142, 1505: 7145, 1506: 7146, 1507: 7147, 1508: 7148, 1509: 7149, 1510: 7150, 1511: 7151, 1512: 7157, 1513: 7159, 1514: 7160, 1515: 7161, 1516: 7162, 1517: 7163, 1518: 7166, 1519: 7167, 1520: 7168, 1521: 7169, 1522: 7170, 1523: 7171, 1524: 7172, 1525: 7174, 1526: 7175, 1527: 7176, 1528: 7177, 1529: 7178, 1530: 7180, 1531: 7181, 1532: 7182, 1533: 7183, 1534: 7189, 1535: 7190, 1536: 7191, 1537: 7192, 1538: 7193, 1539: 7194, 1540: 7195, 1541: 7196, 1542: 7197, 1543: 7198, 1544: 7199, 1545: 7200, 1546: 7201, 1547: 7202, 1548: 7207, 1549: 7208, 1550: 7209, 1551: 7214, 1552: 7215, 1553: 7216, 1554: 7217, 1555: 7218, 1556: 7219, 1557: 7220, 1558: 7221, 1559: 7225, 1560: 7226, 1561: 7227, 1562: 7229, 1563: 7230, 1564: 7231, 1565: 7232, 1566: 7233, 1567: 7234, 1568: 7235, 1569: 7237, 1570: 7238, 1571: 7239, 1572: 7242, 1573: 7253, 1574: 7254, 1575: 7255, 1576: 7256, 1577: 7258, 1578: 7259, 1579: 7260, 1580: 7261, 1581: 7262, 1582: 7264, 1583: 7265, 1584: 7266, 1585: 7267, 1586: 7268, 1587: 7269, 1588: 7270, 1589: 7271, 1590: 7273, 1591: 7274, 1592: 7275, 1593: 7276, 1594: 7277, 1595: 7278, 1596: 7279, 1597: 7281, 1598: 7283, 1599: 7284, 1600: 7285, 1601: 7286, 1602: 7287, 1603: 7288, 1604: 7289, 1605: 7291, 1606: 7292, 1607: 7293, 1608: 7294, 1609: 7295, 1610: 7296, 1611: 7297, 1612: 7298, 1613: 7299, 1614: 7300, 1615: 7301, 1616: 7307, 1617: 7309, 1618: 7311, 1619: 7315, 1620: 7316, 1621: 7317, 1622: 7318, 1623: 7320, 1624: 7322, 1625: 7323, 1626: 7326, 1627: 7327, 1628: 7328, 1629: 7329, 1630: 7330, 1631: 7332, 1632: 7333, 1633: 7334, 1634: 7335, 1635: 7337, 1636: 7338, 1637: 7339, 1638: 7340, 1639: 7342, 1640: 7343, 1641: 7344, 1642: 7346, 1643: 7347, 1644: 7348, 1645: 7349, 1646: 7350, 1647: 7351, 1648: 7352, 1649: 7353, 1650: 7354, 1651: 7355, 1652: 7356, 1653: 7357, 1654: 7358, 1655: 7359, 1656: 7360, 1657: 7361, 1658: 7362, 1659: 7363, 1660: 7365, 1661: 7366, 1662: 7367, 1663: 7368, 1664: 7369, 1665: 7375, 1666: 7376, 1667: 7378, 1668: 7380, 1669: 7382, 1670: 7383, 1671: 7384, 1672: 7388, 1673: 7389, 1674: 7390, 1675: 7391, 1676: 7392, 1677: 7394, 1678: 7398, 1679: 7399, 1680: 7402, 1681: 7403, 1682: 7404, 1683: 7405, 1684: 7406, 1685: 7407, 1686: 7408, 1687: 7410, 1688: 7414, 1689: 7416, 1690: 7417, 1691: 7418, 1692: 7419, 1693: 7420, 1694: 7421, 1695: 7422, 1696: 7424, 1697: 7425, 1698: 7426, 1699: 7427, 1700: 7428, 1701: 7430, 1702: 7431, 1703: 7432, 1704: 7433, 1705: 7434, 1706: 7436, 1707: 7437, 1708: 7438, 1709: 7439, 1710: 7440, 1711: 7441, 1712: 7446, 1713: 7447, 1714: 7448, 1715: 7449, 1716: 7452, 1717: 7453, 1718: 7454, 1719: 7457, 1720: 7458, 1721: 7459, 1722: 7460, 1723: 7461, 1724: 7462, 1725: 7463, 1726: 7464, 1727: 7465, 1728: 7466, 1729: 7467, 1730: 7469, 1731: 7470, 1732: 7472, 1733: 7475, 1734: 7476, 1735: 7477, 1736: 7479, 1737: 7480, 1738: 7482, 1739: 7483, 1740: 7484, 1741: 7486, 1742: 7490, 1743: 7491, 1744: 7492, 1745: 7495, 1746: 7496, 1747: 7497, 1748: 7499, 1749: 7500, 1750: 7501, 1751: 7503, 1752: 7504, 1753: 7505, 1754: 7508, 1755: 7509, 1756: 7510, 1757: 7511, 1758: 7515, 1759: 7519, 1760: 7520, 1761: 7521, 1762: 7525, 1763: 7526, 1764: 7530, 1765: 7531, 1766: 7533, 1767: 7534, 1768: 7535, 1769: 7536, 1770: 7537, 1771: 7538, 1772: 7539, 1773: 7540, 1774: 7541, 1775: 7542, 1776: 7546, 1777: 7548, 1778: 7551, 1779: 7552, 1780: 7554, 1781: 7557, 1782: 7560, 1783: 7561, 1784: 7562, 1785: 7565, 1786: 7569, 1787: 7570, 1788: 7573, 1789: 7580, 1790: 7581, 1791: 7584, 1792: 7585, 1793: 7586, 1794: 7587, 1795: 7589, 1796: 7590, 1797: 7591, 1798: 7594, 1799: 7595, 1800: 7597, 1801: 7598, 1802: 7600, 1803: 7601, 1804: 7605, 1805: 7608, 1806: 7609, 1807: 7610, 1808: 7611, 1809: 7613, 1810: 7617, 1811: 7618, 1812: 7619, 1813: 7621, 1814: 7622, 1815: 7623, 1816: 7628, 1817: 7629, 1818: 7630, 1819: 7631, 1820: 7632, 1821: 7633, 1822: 7634, 1823: 7635, 1824: 7636, 1825: 7637, 1826: 7638, 1827: 7639, 1828: 7640, 1829: 7641, 1830: 7642, 1831: 7643, 1832: 7644, 1833: 7645, 1834: 7646, 1835: 7647, 1836: 7650, 1837: 7654, 1838: 7657, 1839: 7659, 1840: 7660, 1841: 7661, 1842: 7662, 1843: 7663, 1844: 7664, 1845: 7665, 1846: 7667, 1847: 7670, 1848: 7671, 1849: 7673, 1850: 7674, 1851: 7676, 1852: 7678, 1853: 7679, 1854: 7680, 1855: 7681, 1856: 7682, 1857: 7683, 1858: 7685, 1859: 7688, 1860: 7689, 1861: 7690, 1862: 7692, 1863: 7693, 1864: 7695, 1865: 7696, 1866: 7697, 1867: 7698, 1868: 7699, 1869: 7700, 1870: 7701, 1871: 7705, 1872: 7707, 1873: 7708, 1874: 7709, 1875: 7711, 1876: 7712, 1877: 7713, 1878: 7714, 1879: 7716, 1880: 7717, 1881: 7719, 1882: 7720, 1883: 7724, 1884: 7725, 1885: 7726, 1886: 7727, 1887: 7728, 1888: 7729, 1889: 7730, 1890: 7731, 1891: 7733, 1892: 7734, 1893: 7735, 1894: 7736, 1895: 7737, 1896: 7738, 1897: 7739, 1898: 7741, 1899: 7743, 1900: 7744, 1901: 7745, 1902: 7746, 1903: 7747, 1904: 7748, 1905: 7749, 1906: 7750, 1907: 7751, 1908: 7754, 1909: 7755, 1910: 7756, 1911: 7757, 1912: 7758, 1913: 7759, 1914: 7761, 1915: 7762, 1916: 7763, 1917: 7764, 1918: 7765, 1919: 7767, 1920: 7768, 1921: 7771, 1922: 7773, 1923: 7775, 1924: 7776, 1925: 7779, 1926: 7780, 1927: 7781, 1928: 7782, 1929: 7788, 1930: 7789, 1931: 7792, 1932: 7793, 1933: 7796, 1934: 7815, 1935: 7816, 1936: 7818, 1937: 7820, 1938: 7821, 1939: 7822, 1940: 7823, 1941: 7824, 1942: 7825, 1943: 7826, 1944: 7827, 1945: 7828, 1946: 7829, 1947: 7830, 1948: 7831, 1949: 7835, 1950: 7836, 1951: 7837, 1952: 7838, 1953: 7842, 1954: 7844, 1955: 7845, 1956: 7846, 1957: 7847, 1958: 7848, 1959: 7849, 1960: 7851, 1961: 7859, 1962: 7861, 1963: 7862, 1964: 7869, 1965: 7873, 1966: 7881, 1967: 7882, 1968: 7883, 1969: 7884, 1970: 7885, 1971: 7886, 1972: 7887, 1973: 7888, 1974: 7890, 1975: 7891, 1976: 7894, 1977: 7895, 1978: 7899, 1979: 7901, 1980: 7902, 1981: 7903, 1982: 7904, 1983: 7905, 1984: 7906, 1985: 7907, 1986: 7908, 1987: 7911, 1988: 7912, 1989: 7913, 1990: 7914, 1991: 7915, 1992: 7916, 1993: 7917, 1994: 7918, 1995: 7921, 1996: 7922, 1997: 7924, 1998: 7925, 1999: 7928, 2000: 7930, 2001: 7931, 2002: 7932, 2003: 7933, 2004: 7935, 2005: 7936, 2006: 7937, 2007: 7939, 2008: 7940, 2009: 7941, 2010: 7943, 2011: 7944, 2012: 7945, 2013: 7946, 2014: 7947, 2015: 7948, 2016: 7949, 2017: 7951, 2018: 7952, 2019: 7953, 2020: 7954, 2021: 7957, 2022: 7960, 2023: 7962, 2024: 7964, 2025: 7965, 2026: 7966, 2027: 7967, 2028: 7968, 2029: 7969, 2030: 7971, 2031: 7979, 2032: 7980, 2033: 7983, 2034: 7985, 2035: 7988, 2036: 7989, 2037: 7992, 2038: 7993, 2039: 7994, 2040: 7996, 2041: 7998, 2042: 8000, 2043: 8001}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping.keys())[list(mapping.values()).index(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = np.zeros((50000,200,2044),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target in enumerate(summarytok):\n",
    "    for n, word in enumerate(target):\n",
    "        decoder_target[i,n,list(mapping.keys())[list(mapping.values()).index(word)]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEGNTH = 512\n",
    "NUM_WORDS = 2064 #본문 기사 내 가장 많이 사용된 3000단어?(or 전체 단어수로 할지 미정)\n",
    "VECTOR_SIZE = 768\n",
    "MAX_SUMMARIZATION_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = np.array(summarytok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200, 2044)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 512)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Input, Dense, dot, concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Attention():\n",
    "    def __init__(self):\n",
    "        self.max_length = 512\n",
    "        self.VECTOR_SIZE = 768\n",
    "        self.max_summary_length = 200\n",
    "        self.num_words = 2044\n",
    "        \n",
    "        self.sos =  2\n",
    "        self.eos =  3\n",
    "        \n",
    "        self.optimizer = Adam()\n",
    "        \n",
    "        encoder_inputs = Input(shape=(self.max_length,self.VECTOR_SIZE))\n",
    "        decoder_inputs = Input(shape=(self.max_summary_length,self.VECTOR_SIZE))\n",
    "        \n",
    "        self.att = self.build_att()\n",
    "\n",
    "        self.att.compile(loss='categorical_crossentropy', optimizer=self.optimizer)\n",
    "        print(self.att.summary())\n",
    "        \n",
    "        \n",
    "    def build_att(self):\n",
    "        def lstm(inputs, hs, seq=True, initial=None):\n",
    "            output,h,c = LSTM(hs, return_state=True, return_sequences=seq)(inputs, initial_state=initial) \n",
    "            #return_seq=False & return_state=True: return only last h, c\n",
    "            #return_seq=Ture & return_state=True: return all h, c\n",
    "            return output, h, c\n",
    "        \n",
    "        def fc(n_h_layers, inputs, hn):\n",
    "            for _ in range(n_h_layers):\n",
    "                d = Dense(hn, activation='tanh')(inputs)\n",
    "            if n_h_layers==0: \n",
    "                d = inputs\n",
    "            output = Dense(hn, activation='softmax')(d)\n",
    "            #모든 2064개 단어에 대한 확률값 (해당 위치에서의)\n",
    "            return output\n",
    "        \n",
    "        #(encoder input) already embedded from koBERT(vector size 만큼)\n",
    "        encoder_inputs = Input(shape=(self.max_length,self.VECTOR_SIZE))\n",
    "        encoder_outputs, h, c = lstm(encoder_inputs, 256)  #Discard encoder outputs\n",
    "        print(encoder_outputs)\n",
    "        init_states = [h,c]\n",
    "        \n",
    "        decoder_inputs = Input(shape=(self.max_summary_length,self.VECTOR_SIZE))\n",
    "        decoder_outputs, _, _ = lstm(decoder_inputs, 256, initial=init_states) #Discard encoder outputs\n",
    "        \n",
    "        value = Dense(5000, activation='tanh')(encoder_outputs)\n",
    "        query = Dense(5000, activation='tanh')(decoder_outputs)\n",
    "        print(value, query) #300x5000 두개\n",
    "        \n",
    "        attention = dot([query, value],axes=[2,2])\n",
    "        print(attention) #300x300\n",
    "        \n",
    "        attention_softmaxed = fc(0, attention, self.max_length)\n",
    "        print(attention_softmaxed) #300x300\n",
    "        print(encoder_outputs)\n",
    "        \n",
    "        weighted = dot([attention_softmaxed, encoder_outputs], axes=[2,1]) #give weights to encoder outputs(=각 토큰)\n",
    "        print(attention_softmaxed)\n",
    "        \n",
    "        print(weighted)\n",
    "        \n",
    "        decoder_for_final = concatenate([weighted, decoder_outputs]) #weighted token(2064x256) + decoder output(2064x256)\n",
    "        #or add? 둘중에 성능좋은거 고르기\n",
    "        \n",
    "        decoder_final = fc(1, decoder_for_final, self.num_words)\n",
    "        print(decoder_final)\n",
    "        \n",
    "        mod = Model([encoder_inputs, decoder_inputs], decoder_final) \n",
    "        return mod\n",
    "    \n",
    "    #Get data of batch size\n",
    "    def load_batch(self, batch_size=32):\n",
    "        self.n_batches = int(55000/32)\n",
    "        for i in range(self.n_batches):\n",
    "            batch_e = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_d = decoder_input[i*batch_size:(i+1)*batch_size]\n",
    "            batch_d_o = decoder_target[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            enc_ins, dec_ins, dec_out = [],[],[]\n",
    "            for enc_in, dec_in, dec_o in zip(batch_e, batch_d, batch_d_o):\n",
    "                enc_ins.append(enc_in)\n",
    "                dec_ins.append(dec_in)\n",
    "                dec_out.append(dec_o)\n",
    "\n",
    "            yield enc_ins, dec_ins, dec_out\n",
    "    \n",
    "    #train model\n",
    "    def train(self, epochs, batch_size = 32):\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (enc_batch, dec_batch, dec_out_batch) in enumerate(self.load_batch(batch_size)):\n",
    "                \n",
    "                enc_batch = kobert_convert(enc_batch, pytorch_kobert_model)\n",
    "                dec_batch = kobert_convert(dec_batch, pytorch_kobert_model)\n",
    "                \n",
    "                print(np.array(enc_batch).shape, np.array(dec_batch).shape, np.array(dec_out_batch).shape)\n",
    "                \n",
    "                enc_batch = np.array(enc_batch)\n",
    "                dec_batch = np.array(dec_batch)\n",
    "                dec_out_batch = np.array(dec_out_batch)\n",
    "                \n",
    "                att_loss = self.att.train_on_batch([enc_batch, dec_batch], dec_out_batch)\n",
    "                \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                \n",
    "                print(\"[Epoch %d/%d] [Batch %d/%d] Loss: %05f Time:%s\"%(epoch, epochs, batch_i, self.n_batches, att_loss, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_10/Identity:0\", shape=(None, 512, 256), dtype=float32)\n",
      "Tensor(\"dense_25/Identity:0\", shape=(None, 512, 5000), dtype=float32) Tensor(\"dense_26/Identity:0\", shape=(None, 200, 5000), dtype=float32)\n",
      "Tensor(\"dot_10/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"dense_27/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"lstm_10/Identity:0\", shape=(None, 512, 256), dtype=float32)\n",
      "Tensor(\"dense_27/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"dot_11/Identity:0\", shape=(None, 200, 256), dtype=float32)\n",
      "Tensor(\"dense_29/Identity:0\", shape=(None, 200, 2044), dtype=float32)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 512, 768)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 200, 768)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 512, 256), ( 1049600     input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 200, 256), ( 1049600     input_24[0][0]                   \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 200, 5000)    1285000     lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 512, 5000)    1285000     lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 200, 512)     0           dense_26[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 200, 512)     262656      dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 200, 256)     0           dense_27[0][0]                   \n",
      "                                                                 lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 200, 512)     0           dot_11[0][0]                     \n",
      "                                                                 lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 200, 2044)    1048572     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 200, 2044)    4179980     dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,160,408\n",
      "Trainable params: 10,160,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq_Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_14782 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 0/1718] Loss: 7.719460 Time:0:00:16.707360\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 1/1718] Loss: 3.999789 Time:0:00:25.967243\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 2/1718] Loss: 2.364223 Time:0:00:35.160148\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 3/1718] Loss: 2.574915 Time:0:00:44.470148\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 4/1718] Loss: 3.005148 Time:0:00:53.486505\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 5/1718] Loss: 2.015527 Time:0:01:02.620556\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 6/1718] Loss: 1.317814 Time:0:01:11.864740\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 7/1718] Loss: 1.895951 Time:0:01:20.831397\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 8/1718] Loss: 1.423793 Time:0:01:30.174123\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 9/1718] Loss: 1.707424 Time:0:01:39.582345\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 10/1718] Loss: 1.236930 Time:0:01:49.193339\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 11/1718] Loss: 1.297333 Time:0:01:58.472664\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 12/1718] Loss: 1.319636 Time:0:02:07.736709\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 13/1718] Loss: 1.397210 Time:0:02:17.272653\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 14/1718] Loss: 1.353613 Time:0:02:26.559137\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 15/1718] Loss: 1.341664 Time:0:02:35.802642\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 16/1718] Loss: 1.254519 Time:0:02:45.493210\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 17/1718] Loss: 1.116451 Time:0:02:54.668021\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 18/1718] Loss: 1.339155 Time:0:03:03.974972\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 19/1718] Loss: 1.299661 Time:0:03:13.265789\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 20/1718] Loss: 1.223120 Time:0:03:22.646757\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 21/1718] Loss: 1.095533 Time:0:03:31.749475\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 22/1718] Loss: 1.168486 Time:0:03:40.999655\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 23/1718] Loss: 1.046611 Time:0:03:50.308623\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 24/1718] Loss: 1.139642 Time:0:03:59.596859\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 25/1718] Loss: 1.139855 Time:0:04:08.817515\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 26/1718] Loss: 1.054778 Time:0:04:17.998323\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 27/1718] Loss: 1.040949 Time:0:04:27.455779\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 28/1718] Loss: 1.013853 Time:0:04:36.627629\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 29/1718] Loss: 0.986534 Time:0:04:45.943077\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 30/1718] Loss: 0.884373 Time:0:04:55.394351\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 31/1718] Loss: 1.202155 Time:0:05:04.601788\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 32/1718] Loss: 0.933721 Time:0:05:13.923427\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 33/1718] Loss: 0.955981 Time:0:05:23.150877\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 34/1718] Loss: 0.871234 Time:0:05:32.434137\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 35/1718] Loss: 0.980091 Time:0:05:41.690258\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 36/1718] Loss: 1.082756 Time:0:05:51.369042\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 37/1718] Loss: 1.006255 Time:0:06:00.786586\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 38/1718] Loss: 0.917795 Time:0:06:10.060491\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 39/1718] Loss: 0.861643 Time:0:06:19.317406\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 40/1718] Loss: 0.913365 Time:0:06:28.374835\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 41/1718] Loss: 0.924438 Time:0:06:37.526584\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 42/1718] Loss: 0.849946 Time:0:06:46.771011\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 43/1718] Loss: 0.900468 Time:0:06:56.004012\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 44/1718] Loss: 0.966118 Time:0:07:05.168456\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 45/1718] Loss: 0.844982 Time:0:07:14.304911\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 46/1718] Loss: 0.779153 Time:0:07:23.345428\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 47/1718] Loss: 0.816303 Time:0:07:32.482717\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 48/1718] Loss: 0.778104 Time:0:07:41.665733\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 49/1718] Loss: 0.740826 Time:0:07:50.655116\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 50/1718] Loss: 0.677692 Time:0:07:59.916851\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 51/1718] Loss: 0.794908 Time:0:08:08.921856\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 52/1718] Loss: 0.704143 Time:0:08:18.183898\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 53/1718] Loss: 0.767730 Time:0:08:27.331417\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 54/1718] Loss: 0.739042 Time:0:08:36.688392\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 55/1718] Loss: 0.716928 Time:0:08:46.089080\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 56/1718] Loss: 0.657855 Time:0:08:55.258652\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 57/1718] Loss: 0.687737 Time:0:09:04.526593\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 58/1718] Loss: 0.719308 Time:0:09:13.813694\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 59/1718] Loss: 0.735614 Time:0:09:22.929560\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 60/1718] Loss: 0.675797 Time:0:09:32.332171\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 61/1718] Loss: 0.686195 Time:0:09:41.627169\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 62/1718] Loss: 0.722715 Time:0:09:50.851119\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 63/1718] Loss: 0.618486 Time:0:10:00.041043\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 64/1718] Loss: 0.680477 Time:0:10:09.196260\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 65/1718] Loss: 0.645650 Time:0:10:18.802127\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 66/1718] Loss: 0.636658 Time:0:10:28.028592\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 67/1718] Loss: 0.667309 Time:0:10:37.186974\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 68/1718] Loss: 0.483552 Time:0:10:46.655069\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 69/1718] Loss: 0.502041 Time:0:10:55.956333\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 70/1718] Loss: 0.581983 Time:0:11:05.243815\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 71/1718] Loss: 0.633382 Time:0:11:14.380475\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 72/1718] Loss: 0.529304 Time:0:11:23.704122\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 73/1718] Loss: 0.641711 Time:0:11:32.727846\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 74/1718] Loss: 0.561333 Time:0:11:42.123114\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 75/1718] Loss: 0.506929 Time:0:11:51.582084\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 76/1718] Loss: 0.606394 Time:0:12:00.857295\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 77/1718] Loss: 0.566896 Time:0:12:10.080508\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 78/1718] Loss: 0.471387 Time:0:12:19.425103\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 79/1718] Loss: 0.503805 Time:0:12:28.524361\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 80/1718] Loss: 0.524221 Time:0:12:37.688080\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 81/1718] Loss: 0.478062 Time:0:12:47.201538\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 82/1718] Loss: 0.535339 Time:0:12:56.618472\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 83/1718] Loss: 0.449996 Time:0:13:05.750816\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 84/1718] Loss: 0.512813 Time:0:13:14.977949\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 85/1718] Loss: 0.516924 Time:0:13:24.160998\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 86/1718] Loss: 0.543345 Time:0:13:33.418035\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 87/1718] Loss: 0.463417 Time:0:13:42.852031\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 88/1718] Loss: 0.495511 Time:0:13:52.291258\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 89/1718] Loss: 0.517466 Time:0:14:01.563635\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 90/1718] Loss: 0.506209 Time:0:14:10.462009\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 91/1718] Loss: 0.404382 Time:0:14:19.668553\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 92/1718] Loss: 0.419232 Time:0:14:28.937652\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 93/1718] Loss: 0.404120 Time:0:14:38.393019\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 94/1718] Loss: 0.499176 Time:0:14:47.915789\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 95/1718] Loss: 0.464169 Time:0:14:57.010736\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 96/1718] Loss: 0.382988 Time:0:15:06.255816\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 97/1718] Loss: 0.505211 Time:0:15:15.511134\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 98/1718] Loss: 0.464727 Time:0:15:24.864481\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 99/1718] Loss: 0.370817 Time:0:15:34.110744\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 100/1718] Loss: 0.440134 Time:0:15:43.301073\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 101/1718] Loss: 0.404932 Time:0:15:52.417162\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 102/1718] Loss: 0.450328 Time:0:16:01.666550\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 103/1718] Loss: 0.353107 Time:0:16:10.967746\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 104/1718] Loss: 0.467984 Time:0:16:20.130732\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 105/1718] Loss: 0.460200 Time:0:16:29.342467\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 106/1718] Loss: 0.430579 Time:0:16:38.567781\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 107/1718] Loss: 0.347736 Time:0:16:48.142790\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 108/1718] Loss: 0.388790 Time:0:16:57.300352\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 109/1718] Loss: 0.439876 Time:0:17:06.365445\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 110/1718] Loss: 0.365207 Time:0:17:15.433380\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 111/1718] Loss: 0.408165 Time:0:17:24.875595\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 112/1718] Loss: 0.396302 Time:0:17:34.074933\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 113/1718] Loss: 0.405180 Time:0:17:43.328574\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 114/1718] Loss: 0.422893 Time:0:17:52.541862\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 115/1718] Loss: 0.386661 Time:0:18:01.763035\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 116/1718] Loss: 0.375405 Time:0:18:10.895760\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 117/1718] Loss: 0.405487 Time:0:18:20.066139\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 118/1718] Loss: 0.406925 Time:0:18:29.150877\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 119/1718] Loss: 0.451981 Time:0:18:38.366816\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 120/1718] Loss: 0.395032 Time:0:18:47.339093\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 121/1718] Loss: 0.353085 Time:0:18:56.314715\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 122/1718] Loss: 0.382164 Time:0:19:05.557687\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 123/1718] Loss: 0.428722 Time:0:19:14.761956\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 124/1718] Loss: 0.392664 Time:0:19:24.012224\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 125/1718] Loss: 0.350125 Time:0:19:33.155518\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 126/1718] Loss: 0.357285 Time:0:19:42.311119\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 127/1718] Loss: 0.375883 Time:0:19:51.797113\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 128/1718] Loss: 0.378720 Time:0:20:01.195958\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 129/1718] Loss: 0.371424 Time:0:20:10.196190\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 130/1718] Loss: 0.422720 Time:0:20:19.421253\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 131/1718] Loss: 0.382056 Time:0:20:28.648390\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 132/1718] Loss: 0.360762 Time:0:20:37.884878\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 133/1718] Loss: 0.352198 Time:0:20:47.267517\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 134/1718] Loss: 0.339063 Time:0:20:56.457496\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 135/1718] Loss: 0.365179 Time:0:21:05.703709\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 136/1718] Loss: 0.357027 Time:0:21:15.009916\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 137/1718] Loss: 0.343448 Time:0:21:24.090469\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 138/1718] Loss: 0.352334 Time:0:21:33.250627\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 139/1718] Loss: 0.324470 Time:0:21:42.388258\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 140/1718] Loss: 0.372039 Time:0:21:51.784627\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 141/1718] Loss: 0.347048 Time:0:22:00.842038\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 142/1718] Loss: 0.325525 Time:0:22:10.008971\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 143/1718] Loss: 0.307751 Time:0:22:19.087427\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 144/1718] Loss: 0.346666 Time:0:22:28.205762\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 145/1718] Loss: 0.345522 Time:0:22:37.329443\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 146/1718] Loss: 0.336577 Time:0:22:46.832146\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 147/1718] Loss: 0.338144 Time:0:22:56.029947\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 148/1718] Loss: 0.338821 Time:0:23:05.192502\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 149/1718] Loss: 0.373875 Time:0:23:14.359130\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 150/1718] Loss: 0.326731 Time:0:23:23.758140\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 151/1718] Loss: 0.330939 Time:0:23:32.949026\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 152/1718] Loss: 0.344116 Time:0:23:42.114681\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 153/1718] Loss: 0.294254 Time:0:23:51.637304\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 154/1718] Loss: 0.319259 Time:0:24:00.764602\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 155/1718] Loss: 0.342168 Time:0:24:09.865508\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 156/1718] Loss: 0.293865 Time:0:24:19.088285\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 157/1718] Loss: 0.285053 Time:0:24:28.084004\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 158/1718] Loss: 0.262243 Time:0:24:37.227265\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 159/1718] Loss: 0.279349 Time:0:24:46.363303\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 160/1718] Loss: 0.304206 Time:0:24:55.571292\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 161/1718] Loss: 0.255027 Time:0:25:04.789418\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 162/1718] Loss: 0.293956 Time:0:25:14.038780\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 163/1718] Loss: 0.317983 Time:0:25:23.272056\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 164/1718] Loss: 0.307487 Time:0:25:32.487308\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 165/1718] Loss: 0.288570 Time:0:25:41.723544\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 166/1718] Loss: 0.280719 Time:0:25:51.336216\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 167/1718] Loss: 0.283232 Time:0:26:00.633023\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 168/1718] Loss: 0.300895 Time:0:26:09.792794\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 169/1718] Loss: 0.284284 Time:0:26:19.053394\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 170/1718] Loss: 0.280314 Time:0:26:28.198048\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 171/1718] Loss: 0.282033 Time:0:26:37.581170\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 172/1718] Loss: 0.317389 Time:0:26:47.150034\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 173/1718] Loss: 0.299489 Time:0:26:56.312506\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 174/1718] Loss: 0.277048 Time:0:27:05.590777\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 175/1718] Loss: 0.257882 Time:0:27:14.737957\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 176/1718] Loss: 0.301224 Time:0:27:23.925856\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 177/1718] Loss: 0.285171 Time:0:27:33.108009\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 178/1718] Loss: 0.259992 Time:0:27:42.246737\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 179/1718] Loss: 0.239411 Time:0:27:51.748113\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 180/1718] Loss: 0.241048 Time:0:28:00.959346\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 181/1718] Loss: 0.280726 Time:0:28:10.116140\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 182/1718] Loss: 0.279397 Time:0:28:19.479364\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 183/1718] Loss: 0.262540 Time:0:28:28.683736\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 184/1718] Loss: 0.225666 Time:0:28:37.898823\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 185/1718] Loss: 0.252860 Time:0:28:47.324689\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 186/1718] Loss: 0.262734 Time:0:28:56.614637\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 187/1718] Loss: 0.266751 Time:0:29:05.837585\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 188/1718] Loss: 0.222460 Time:0:29:14.952657\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 189/1718] Loss: 0.226134 Time:0:29:24.157891\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 190/1718] Loss: 0.249862 Time:0:29:33.281010\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 191/1718] Loss: 0.260604 Time:0:29:42.430872\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 192/1718] Loss: 0.238592 Time:0:29:51.929209\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 193/1718] Loss: 0.242421 Time:0:30:01.348093\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 194/1718] Loss: 0.244540 Time:0:30:10.593992\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 195/1718] Loss: 0.262375 Time:0:30:19.776220\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 196/1718] Loss: 0.207927 Time:0:30:28.974287\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 197/1718] Loss: 0.258499 Time:0:30:38.378874\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 198/1718] Loss: 0.206415 Time:0:30:47.558027\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 199/1718] Loss: 0.249507 Time:0:30:56.665862\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 200/1718] Loss: 0.217822 Time:0:31:05.944236\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 201/1718] Loss: 0.229816 Time:0:31:15.077406\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 202/1718] Loss: 0.250567 Time:0:31:24.295085\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 203/1718] Loss: 0.221404 Time:0:31:33.639100\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 204/1718] Loss: 0.226882 Time:0:31:42.985872\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 205/1718] Loss: 0.233909 Time:0:31:52.282941\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 206/1718] Loss: 0.193632 Time:0:32:01.677817\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 207/1718] Loss: 0.222199 Time:0:32:11.017067\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 208/1718] Loss: 0.229096 Time:0:32:20.246344\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 209/1718] Loss: 0.228202 Time:0:32:29.364782\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 210/1718] Loss: 0.232208 Time:0:32:38.617837\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 211/1718] Loss: 0.240617 Time:0:32:48.124253\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 212/1718] Loss: 0.227407 Time:0:32:57.219922\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 213/1718] Loss: 0.208523 Time:0:33:06.374108\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 214/1718] Loss: 0.224111 Time:0:33:15.578454\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 215/1718] Loss: 0.219768 Time:0:33:24.767632\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 216/1718] Loss: 0.194829 Time:0:33:33.965581\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 217/1718] Loss: 0.205336 Time:0:33:43.146381\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 218/1718] Loss: 0.217785 Time:0:33:52.357915\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 219/1718] Loss: 0.195692 Time:0:34:01.886185\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 220/1718] Loss: 0.225442 Time:0:34:11.047553\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 221/1718] Loss: 0.226009 Time:0:34:20.232906\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 222/1718] Loss: 0.204089 Time:0:34:29.592090\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 223/1718] Loss: 0.237599 Time:0:34:38.779694\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 224/1718] Loss: 0.204960 Time:0:34:48.506957\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 225/1718] Loss: 0.187887 Time:0:34:57.876967\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 226/1718] Loss: 0.195529 Time:0:35:07.094617\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 227/1718] Loss: 0.218203 Time:0:35:16.353421\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 228/1718] Loss: 0.207729 Time:0:35:25.483162\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 229/1718] Loss: 0.199011 Time:0:35:34.934111\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 230/1718] Loss: 0.203915 Time:0:35:44.244099\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 231/1718] Loss: 0.189710 Time:0:35:53.500413\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 232/1718] Loss: 0.218519 Time:0:36:02.785452\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 233/1718] Loss: 0.229102 Time:0:36:11.903347\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 234/1718] Loss: 0.195412 Time:0:36:21.290686\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 235/1718] Loss: 0.205903 Time:0:36:30.629816\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 236/1718] Loss: 0.207784 Time:0:36:39.834961\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 237/1718] Loss: 0.187296 Time:0:36:49.100705\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 238/1718] Loss: 0.206974 Time:0:36:58.363940\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 239/1718] Loss: 0.169274 Time:0:37:07.679123\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 240/1718] Loss: 0.189353 Time:0:37:16.799603\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 241/1718] Loss: 0.175989 Time:0:37:26.052910\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 242/1718] Loss: 0.207823 Time:0:37:35.144147\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 243/1718] Loss: 0.177641 Time:0:37:44.395122\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 244/1718] Loss: 0.202194 Time:0:37:53.632782\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 245/1718] Loss: 0.183005 Time:0:38:02.762615\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 246/1718] Loss: 0.209392 Time:0:38:11.987161\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 247/1718] Loss: 0.191179 Time:0:38:21.585001\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 248/1718] Loss: 0.195643 Time:0:38:30.647535\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 249/1718] Loss: 0.171092 Time:0:38:39.966251\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 250/1718] Loss: 0.174021 Time:0:38:49.314591\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 251/1718] Loss: 0.189753 Time:0:38:58.493006\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 252/1718] Loss: 0.187605 Time:0:39:07.724620\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 253/1718] Loss: 0.169613 Time:0:39:16.900138\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 254/1718] Loss: 0.180971 Time:0:39:26.113214\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 255/1718] Loss: 0.188658 Time:0:39:35.398828\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 256/1718] Loss: 0.168825 Time:0:39:44.604368\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 257/1718] Loss: 0.219976 Time:0:39:53.712988\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 258/1718] Loss: 0.175032 Time:0:40:02.840783\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 259/1718] Loss: 0.185701 Time:0:40:12.113974\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 260/1718] Loss: 0.179818 Time:0:40:21.240549\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 261/1718] Loss: 0.191821 Time:0:40:30.435707\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 262/1718] Loss: 0.163508 Time:0:40:39.664743\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 263/1718] Loss: 0.183973 Time:0:40:49.118125\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 264/1718] Loss: 0.181328 Time:0:40:58.488757\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 265/1718] Loss: 0.175080 Time:0:41:07.757771\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 266/1718] Loss: 0.204605 Time:0:41:16.986225\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 267/1718] Loss: 0.181849 Time:0:41:26.430012\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 268/1718] Loss: 0.194177 Time:0:41:35.870904\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 269/1718] Loss: 0.158470 Time:0:41:45.125221\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 270/1718] Loss: 0.188764 Time:0:41:54.385370\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 271/1718] Loss: 0.168425 Time:0:42:04.077053\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 272/1718] Loss: 0.190594 Time:0:42:13.299292\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 273/1718] Loss: 0.176248 Time:0:42:22.711194\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 274/1718] Loss: 0.189533 Time:0:42:31.818428\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 275/1718] Loss: 0.174241 Time:0:42:41.118919\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 276/1718] Loss: 0.162462 Time:0:42:50.587449\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 277/1718] Loss: 0.159541 Time:0:42:59.848020\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 278/1718] Loss: 0.171736 Time:0:43:09.132224\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 279/1718] Loss: 0.180336 Time:0:43:18.533137\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 280/1718] Loss: 0.190356 Time:0:43:27.663706\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 281/1718] Loss: 0.184966 Time:0:43:36.936836\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 282/1718] Loss: 0.155262 Time:0:43:46.635431\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 283/1718] Loss: 0.194832 Time:0:43:55.784891\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 284/1718] Loss: 0.168988 Time:0:44:04.904675\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 285/1718] Loss: 0.164617 Time:0:44:14.231914\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 286/1718] Loss: 0.178613 Time:0:44:23.570878\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 287/1718] Loss: 0.163512 Time:0:44:33.146172\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 288/1718] Loss: 0.141289 Time:0:44:42.624443\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 289/1718] Loss: 0.172250 Time:0:44:52.160864\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 290/1718] Loss: 0.167812 Time:0:45:01.546861\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 291/1718] Loss: 0.161346 Time:0:45:10.987882\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 292/1718] Loss: 0.144415 Time:0:45:20.258471\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 293/1718] Loss: 0.174383 Time:0:45:29.586331\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 294/1718] Loss: 0.156212 Time:0:45:38.781171\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 295/1718] Loss: 0.132249 Time:0:45:48.030449\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 296/1718] Loss: 0.156887 Time:0:45:57.355832\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 297/1718] Loss: 0.156601 Time:0:46:06.596672\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 298/1718] Loss: 0.157008 Time:0:46:15.902375\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 299/1718] Loss: 0.155088 Time:0:46:25.018974\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 300/1718] Loss: 0.158849 Time:0:46:34.421659\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 301/1718] Loss: 0.153658 Time:0:46:43.751237\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 302/1718] Loss: 0.146592 Time:0:46:53.256989\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 303/1718] Loss: 0.163529 Time:0:47:02.667689\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 304/1718] Loss: 0.185102 Time:0:47:11.996497\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 305/1718] Loss: 0.135863 Time:0:47:21.472957\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 306/1718] Loss: 0.159882 Time:0:47:30.789282\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 307/1718] Loss: 0.138040 Time:0:47:40.082531\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 308/1718] Loss: 0.180547 Time:0:47:49.803565\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 309/1718] Loss: 0.151482 Time:0:47:58.886023\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 310/1718] Loss: 0.157374 Time:0:48:08.101869\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 311/1718] Loss: 0.160650 Time:0:48:17.256858\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 312/1718] Loss: 0.169748 Time:0:48:26.622635\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 313/1718] Loss: 0.175320 Time:0:48:35.929443\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 314/1718] Loss: 0.150846 Time:0:48:45.071477\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 315/1718] Loss: 0.159139 Time:0:48:54.247109\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 316/1718] Loss: 0.159523 Time:0:49:03.960233\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 317/1718] Loss: 0.151953 Time:0:49:13.155542\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 318/1718] Loss: 0.177139 Time:0:49:22.538157\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 319/1718] Loss: 0.167218 Time:0:49:31.760950\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 320/1718] Loss: 0.162756 Time:0:49:40.995832\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 321/1718] Loss: 0.177501 Time:0:49:50.640458\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 322/1718] Loss: 0.144257 Time:0:49:59.829923\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 323/1718] Loss: 0.139542 Time:0:50:08.975764\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 324/1718] Loss: 0.156451 Time:0:50:18.223422\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 325/1718] Loss: 0.156537 Time:0:50:27.425739\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 326/1718] Loss: 0.177587 Time:0:50:36.712923\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 327/1718] Loss: 0.151885 Time:0:50:45.865615\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 328/1718] Loss: 0.157803 Time:0:50:55.021481\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 329/1718] Loss: 0.157029 Time:0:51:04.494330\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 330/1718] Loss: 0.172552 Time:0:51:13.763326\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 331/1718] Loss: 0.139967 Time:0:51:22.994210\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 332/1718] Loss: 0.135432 Time:0:51:32.276973\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 333/1718] Loss: 0.123301 Time:0:51:41.546678\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 334/1718] Loss: 0.156917 Time:0:51:50.764823\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 335/1718] Loss: 0.166652 Time:0:52:00.040384\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 336/1718] Loss: 0.120416 Time:0:52:09.236456\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 337/1718] Loss: 0.163256 Time:0:52:18.502330\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 338/1718] Loss: 0.139662 Time:0:52:28.548998\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 339/1718] Loss: 0.149947 Time:0:52:37.792896\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 340/1718] Loss: 0.145350 Time:0:52:46.992304\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 341/1718] Loss: 0.141503 Time:0:52:56.392653\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 342/1718] Loss: 0.161893 Time:0:53:05.584139\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 343/1718] Loss: 0.144975 Time:0:53:14.909556\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 344/1718] Loss: 0.145015 Time:0:53:24.155655\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 345/1718] Loss: 0.147400 Time:0:53:33.435659\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 346/1718] Loss: 0.152162 Time:0:53:42.666012\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 347/1718] Loss: 0.135942 Time:0:53:52.147207\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 348/1718] Loss: 0.131877 Time:0:54:01.336293\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 349/1718] Loss: 0.127829 Time:0:54:10.524046\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 350/1718] Loss: 0.126431 Time:0:54:19.804316\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 351/1718] Loss: 0.132590 Time:0:54:29.121096\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 352/1718] Loss: 0.139918 Time:0:54:38.211039\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 353/1718] Loss: 0.139917 Time:0:54:47.059016\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 354/1718] Loss: 0.141996 Time:0:54:56.080151\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 355/1718] Loss: 0.127170 Time:0:55:05.189032\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 356/1718] Loss: 0.136426 Time:0:55:14.233435\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 357/1718] Loss: 0.155981 Time:0:55:23.355541\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 358/1718] Loss: 0.163210 Time:0:55:32.622066\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 359/1718] Loss: 0.130045 Time:0:55:41.971652\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 360/1718] Loss: 0.105385 Time:0:55:51.958648\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 361/1718] Loss: 0.135434 Time:0:56:01.771842\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 362/1718] Loss: 0.129451 Time:0:56:11.210761\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 363/1718] Loss: 0.140461 Time:0:56:20.280740\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 364/1718] Loss: 0.130452 Time:0:56:29.516814\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 365/1718] Loss: 0.118296 Time:0:56:38.751846\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 366/1718] Loss: 0.118344 Time:0:56:48.037039\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 367/1718] Loss: 0.140709 Time:0:56:57.334296\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 368/1718] Loss: 0.108203 Time:0:57:06.709496\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 369/1718] Loss: 0.127932 Time:0:57:15.954973\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 370/1718] Loss: 0.125061 Time:0:57:25.196498\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 371/1718] Loss: 0.129203 Time:0:57:34.137894\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 372/1718] Loss: 0.139749 Time:0:57:43.278083\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 373/1718] Loss: 0.116745 Time:0:57:52.585882\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 374/1718] Loss: 0.126999 Time:0:58:01.873568\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 375/1718] Loss: 0.121798 Time:0:58:11.058675\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 376/1718] Loss: 0.109657 Time:0:58:20.226399\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 377/1718] Loss: 0.128282 Time:0:58:29.461580\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 378/1718] Loss: 0.103508 Time:0:58:38.813246\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 379/1718] Loss: 0.113249 Time:0:58:48.331526\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 380/1718] Loss: 0.119304 Time:0:58:57.645359\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 381/1718] Loss: 0.127952 Time:0:59:07.157927\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 382/1718] Loss: 0.126195 Time:0:59:17.895285\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 383/1718] Loss: 0.137072 Time:0:59:31.310963\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 384/1718] Loss: 0.117234 Time:0:59:41.898016\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 385/1718] Loss: 0.123081 Time:0:59:51.361779\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 386/1718] Loss: 0.127336 Time:1:00:00.854931\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 387/1718] Loss: 0.128570 Time:1:00:09.922882\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 388/1718] Loss: 0.149862 Time:1:00:19.108654\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 389/1718] Loss: 0.128208 Time:1:00:28.462207\n",
      "(32, 512, 768) (32, 200, 768) (32, 200, 2044)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 390/1718] Loss: 0.152839 Time:1:00:37.753764\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
