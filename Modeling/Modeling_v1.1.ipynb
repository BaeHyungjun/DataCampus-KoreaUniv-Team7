{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from kobert_transformers import get_kobert_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kobert_transformers import get_tokenizer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True) \n",
    "#코드 실행 전에 추가해주면 연산을 할때 어떤 장치에 할당 되었는지 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_normalized.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>body_morphs</th>\n",
       "      <th>summary_morphs</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이총리 \"폭염, 특별재난 준해…전기요금 제한적 특별배려 검토\"</td>\n",
       "      <td>2018.07.31. 오전 11:53</td>\n",
       "      <td>국무회의 주재···체계적 폭염대책 주문\"최저임금 명암···변화 수용하되 진통 최소화...</td>\n",
       "      <td>이낙연 국무총리는 31일 계속되는 폭염으로 전기요금 부담에 대한 우려가 커지고 있는...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[국무회의, 주재···체계적, 폭염대책, 주문, 최저임금, 명암···변화, 수용, ...</td>\n",
       "      <td>[이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려, 는, 관...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>김성태 \"盧 탄핵때도 기무사 대응문건 의혹…즉시 제출하라\"</td>\n",
       "      <td>2018.07.31. 오전 10:25</td>\n",
       "      <td>\"대통령, 여름휴가 때 노동자·소상공인 생각하길\"김성태 자유한국당 원내대표. = 김...</td>\n",
       "      <td>김성태 자유한국당 원내대표는 31일 \"지난 2004년 노무현 전 대통령 탄핵 당시 ...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[대통령, 여름휴가, 노동자·소상공, 생각하길\"김성태, 자유한국당, 원내대표, =,...</td>\n",
       "      <td>[김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄핵, 당시...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>합참, 北 ICBM 제작 정황 보도에 \"면밀히 추적·감시중\"</td>\n",
       "      <td>2018.07.31. 오전 11:29</td>\n",
       "      <td>노재천 공보실장 \"공식확인 부적절···한미간 공조\"워싱턴포스트 \"액화연료 사용 IC...</td>\n",
       "      <td>합동참모본부는 31일 북한이 대륙간탄도미사일을 만들고 있는 정황을 포착했다는 보도와...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[노재천, 공보실장, 공식확인, 부적절···한미간, 공조\"워싱턴포스트, 액화연료, ...</td>\n",
       "      <td>[합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포착, 었다...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>기무사 \"盧 대통령 탄핵 당시 계엄검토 문건 작성 안해\"</td>\n",
       "      <td>2018.07.31. 오후 2:43</td>\n",
       "      <td>김성태 의원 주장에 반박···지난 정부에서도 관련 내용 확인 국방부 특별수사단이 계...</td>\n",
       "      <td>국군기무사령부는 31일 노무현 전 대통령 탄핵 당시 계엄령 문건을 작성했다는 김성태...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[김성태, 의원, 주장, 반박···지난, 정부, 에서도, 관련, 내용, 확인, 국방...</td>\n",
       "      <td>[국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건, 작성, ...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>'종전문제 다룰까' 北, 이례적 회담 제의 이어 전향적 태도 보여</td>\n",
       "      <td>2018.07.31. 오후 12:55</td>\n",
       "      <td>안익산 대표 \" 흔들어 종전선언? 보도, 그럴 수 있다\" 이해 안익산 북측 수석대표...</td>\n",
       "      <td>북한이 이례적으로 남북 장성급 군사회담을 먼저 제의한데 이어 회담에서 전향적인 태도...</td>\n",
       "      <td>https://news.naver.com/main/ranking/read.nhn?r...</td>\n",
       "      <td>[안익산, 대표, 흔들, 종전선언, ?, 보도, 이해, 안익산, 북측, 수석대표, ...</td>\n",
       "      <td>[북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, 회담, 전...</td>\n",
       "      <td>naver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                 title                  date  \\\n",
       "0   1    이총리 \"폭염, 특별재난 준해…전기요금 제한적 특별배려 검토\"  2018.07.31. 오전 11:53   \n",
       "1   2      김성태 \"盧 탄핵때도 기무사 대응문건 의혹…즉시 제출하라\"  2018.07.31. 오전 10:25   \n",
       "2   3     합참, 北 ICBM 제작 정황 보도에 \"면밀히 추적·감시중\"  2018.07.31. 오전 11:29   \n",
       "3   4       기무사 \"盧 대통령 탄핵 당시 계엄검토 문건 작성 안해\"   2018.07.31. 오후 2:43   \n",
       "4   5  '종전문제 다룰까' 北, 이례적 회담 제의 이어 전향적 태도 보여  2018.07.31. 오후 12:55   \n",
       "\n",
       "                                                body  \\\n",
       "0  국무회의 주재···체계적 폭염대책 주문\"최저임금 명암···변화 수용하되 진통 최소화...   \n",
       "1  \"대통령, 여름휴가 때 노동자·소상공인 생각하길\"김성태 자유한국당 원내대표. = 김...   \n",
       "2  노재천 공보실장 \"공식확인 부적절···한미간 공조\"워싱턴포스트 \"액화연료 사용 IC...   \n",
       "3  김성태 의원 주장에 반박···지난 정부에서도 관련 내용 확인 국방부 특별수사단이 계...   \n",
       "4  안익산 대표 \" 흔들어 종전선언? 보도, 그럴 수 있다\" 이해 안익산 북측 수석대표...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  이낙연 국무총리는 31일 계속되는 폭염으로 전기요금 부담에 대한 우려가 커지고 있는...   \n",
       "1  김성태 자유한국당 원내대표는 31일 \"지난 2004년 노무현 전 대통령 탄핵 당시 ...   \n",
       "2  합동참모본부는 31일 북한이 대륙간탄도미사일을 만들고 있는 정황을 포착했다는 보도와...   \n",
       "3  국군기무사령부는 31일 노무현 전 대통령 탄핵 당시 계엄령 문건을 작성했다는 김성태...   \n",
       "4  북한이 이례적으로 남북 장성급 군사회담을 먼저 제의한데 이어 회담에서 전향적인 태도...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "1  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "2  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "3  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "4  https://news.naver.com/main/ranking/read.nhn?r...   \n",
       "\n",
       "                                         body_morphs  \\\n",
       "0  [국무회의, 주재···체계적, 폭염대책, 주문, 최저임금, 명암···변화, 수용, ...   \n",
       "1  [대통령, 여름휴가, 노동자·소상공, 생각하길\"김성태, 자유한국당, 원내대표, =,...   \n",
       "2  [노재천, 공보실장, 공식확인, 부적절···한미간, 공조\"워싱턴포스트, 액화연료, ...   \n",
       "3  [김성태, 의원, 주장, 반박···지난, 정부, 에서도, 관련, 내용, 확인, 국방...   \n",
       "4  [안익산, 대표, 흔들, 종전선언, ?, 보도, 이해, 안익산, 북측, 수석대표, ...   \n",
       "\n",
       "                                      summary_morphs   site  \n",
       "0  [이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려, 는, 관...  naver  \n",
       "1  [김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄핵, 당시...  naver  \n",
       "2  [합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포착, 었다...  naver  \n",
       "3  [국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건, 작성, ...  naver  \n",
       "4  [북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, 회담, 전...  naver  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리가없어...5만개로 줄여보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 본문 정수인코딩 + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmorphs = data.body_morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "m = 512\n",
    "cnt= 0\n",
    "for n,_ in enumerate(bmorphs):\n",
    "    if len(_)>m:\n",
    "        l.append(n)\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28328"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodytok = []\n",
    "for _ in bmorphs:\n",
    "    bid = tok.convert_tokens_to_ids(_)\n",
    "    if(len(bid)<512):\n",
    "        new = bid+[1]*(512-len(bid)) #padded part = 1\n",
    "    elif(len(bid)>512):\n",
    "        new = bid[:512]\n",
    "    bodytok.append(new)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[5821, 0, 0, 0, 0, 0, 254, 0, 0, 0, 147, 0, 0, 5821, 0, 0, 0, 0, 0, 8, 0, 7782, 5585, 0, 0, 6556, 0, 5511, 0, 0, 0, 0, 6903, 0, 0, 7096, 0, 6210, 0, 0, 0, 7157, 7096, 0, 6157, 0, 5760, 0, 6544, 0, 0, 0, 0, 6888, 54, 5585, 0, 5760, 8, 5725, 5821, 0, 0, 0, 5516, 0, 0, 0, 6903, 0, 7088, 0, 7782, 0, 0, 7096, 0, 5439, 0, 8, 0, 0, 6484, 0, 0, 5507, 0, 0, 6903, 0, 7782, 8, 5439, 0, 7782, 6888, 54, 7096, 7096, 6855, 8, 0, 0, 6903, 5512, 7096, 0, 7088, 0, 7782, 5760, 7884, 5760, 5503, 5330, 0, 0, 6903, 0, 0, 8, 7096, 6008, 0, 5330, 0, 7782, 0, 0, 5859, 0, 0, 0, 0, 5886, 0, 0, 7096, 0, 6157, 7096, 5330, 5439, 0, 7096, 5770, 0, 7096, 5770, 7782, 0, 0, 6797, 0, 7782, 0, 5886, 0, 8, 5439, 0, 7782, 6888, 54, 0, 0, 0, 6896, 6855, 7782, 6855, 8, 0, 0, 5585, 0, 0, 7096, 0, 0, 6896, 0, 7782, 5760, 0, 7088, 5439, 6797, 0, 6855, 0, 0, 6116, 0, 8, 0, 5760, 0, 0, 7096, 0, 0, 7088, 5439, 0, 6116, 6940, 0, 6116, 7782, 0, 7096, 0, 0, 5330, 6166, 5760, 0, 7088, 7782, 6855, 0, 6797, 8, 5439, 0, 7782, 6888, 54, 0, 7095, 0, 7096, 0, 0, 7088, 0, 7782, 0, 0, 6896, 5808, 6855, 7782, 6855, 0, 5760, 0, 5330, 0, 6855, 5516, 0, 0, 7088, 7734, 0, 5821, 7096, 6896, 0, 7096, 5859, 0, 5943, 0, 7088, 6300, 0, 8, 0, 6896, 0, 7782, 0, 7463, 7096, 0, 5512, 7095, 0, 7096, 5400, 0, 6896, 0, 5400, 5698, 6855, 5330, 0, 0, 0, 7782, 0, 8, 7096, 6003, 5439, 0, 6888, 54, 7096, 7096, 6855, 0, 0, 0, 7096, 6005, 6416, 6573, 0, 6896, 5808, 6855, 7782, 6855, 0, 7088, 5413, 5439, 7141, 5760, 8, 6008, 8, 7096, 6416, 7096, 5516, 0, 5369, 7088, 0, 7782, 0, 5398, 7086, 0, 7096, 54, 0, 0, 6116, 0, 0, 5886, 0, 0, 7096, 7141, 5761, 46, 0, 7096, 0, 7230, 0, 0, 7096, 5475, 7096, 0, 0, 7782, 5400, 0, 6003, 8, 5439, 0, 7782, 6888, 54, 5585, 0, 0, 5760, 0, 7095, 0, 6896, 6855, 5330, 0, 6234, 5821, 7088, 0, 6855, 8, 0, 7782, 5400, 0, 6896, 0, 7096, 0, 0, 0, 7095, 0, 7088, 7782, 5760, 0, 5330, 0, 0, 8, 7096, 0, 6896, 0, 7095, 0, 7096, 7979, 5439, 7141, 0, 0, 7145, 7318, 6003, 8, 5439, 0, 7782, 6888, 54, 5585, 0, 0, 5760, 7230, 5330, 6300, 7782, 0, 0, 6896, 5808, 6855, 7782, 6855, 8, 0, 6896, 0, 7088, 6889, 0, 5859, 6578, 7096, 0, 6896, 0, 7088, 5907, 5760, 0, 6578, 0, 6116, 0, 5439, 0, 8, 0, 0, 6896, 7096, 7096, 6855, 0, 0, 7096, 6332, 6855, 7318, 0, 7688, 8, 7096, 6003, 5439, 7005, 7096, 0, 7782, 6888, 54, 7096, 7096, 6855, 8, 0, 7788, 0, 0, 7088, 6218, 0, 0, 0, 6578, 6896, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(bodytok[1]))\n",
    "print(bodytok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 93, 463, 0, 0, 0, 0, 0, 0, 147, 6415, 0, 0, 0, 0, 0, 0, 0, 7088, 0, 5477, 5875, 7088, 0, 7461, 478, 0, 0, 0, 7088, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 7945, 0, 8, 0, 0, 0, 6415, 0, 7337, 0, 5477, 0, 6896, 7782, 0, 7461, 478, 0, 7141, 8, 7782, 54, 0, 0, 5760, 0, 0, 7096, 6415, 0, 0, 0, 7088, 0, 7782, 6888, 5439, 0, 7782, 6888, 54, 0, 5760, 7460, 0, 7457, 0, 0, 7086, 0, 7088, 0, 0, 0, 0, 7782, 5760, 0, 93, 463, 0, 0, 7096, 6855, 5760, 0, 7096, 7141, 5782, 5439, 0, 7782, 6888, 54, 0, 0, 7782, 0, 0, 0, 0, 0, 7096, 0, 0, 5760, 0, 0, 7782, 0, 7141, 5782, 5439, 6415, 7096, 0, 7782, 0, 6273, 7141, 5760, 7430, 7369, 0, 7096, 0, 0, 5451, 7096, 5782, 54, 0, 5760, 6415, 7096, 7859, 5766, 7088, 0, 7788, 7141, 5782, 5439, 0, 7782, 0, 5760, 5782, 5439, 7782, 6888, 54, 0, 0, 6256, 5821, 7096, 0, 0, 7096, 5782, 5439, 0, 0, 6901, 6415, 7096, 0, 0, 6929, 0, 7782, 0, 7088, 5997, 7782, 5439, 0, 7782, 6888, 54, 0, 7095, 0, 7096, 0, 5760, 0, 6855, 7318, 7318, 0, 7945, 5886, 0, 6415, 7096, 6256, 0, 0, 6116, 0, 7782, 0, 7096, 0, 6712, 0, 7088, 0, 7782, 5760, 7096, 0, 7096, 5886, 0, 6629, 5859, 7141, 5782, 54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(bodytok[2]))\n",
    "print(bodytok[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 512)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input = np.array(bodytok)\n",
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary 정수인코딩 + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smorphs = data.summary_morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smorphs = smorphs.apply(lambda x : ['sos']+x+['eos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [sos, 이낙연, 국무총리, 31일, 계속, 는, 폭염, 전기요금, 부담, 우려,...\n",
       "1    [sos, 김성태, 자유한국당, 원내대표, 31, 2004년, 노무현, 대통령, 탄...\n",
       "2    [sos, 합동참모본부, 31, 북한, 이, 대륙간탄도미사일, 는, 정황, 을, 포...\n",
       "3    [sos, 국군기무사령부, 31일, 노무현, 대통령, 탄핵, 당시, 계엄령, 문건,...\n",
       "4    [sos, 북한, 이례적, 남북, 장성급, 군사회담, 먼저, 제의한데, 이, 이, ...\n",
       "Name: summary_morphs, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smorphs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "m = 200\n",
    "cnt= 0\n",
    "for n,_ in enumerate(smorphs):\n",
    "    if len(_)>m:\n",
    "        l.append(n)\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[289, 384, 1086, 1194, 1355]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = get_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to check unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for _ in smorphs:\n",
    "    el_id = tok.convert_tokens_to_ids(_)\n",
    "    tmp.append(el_id)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = set()\n",
    "for lst in tmp:\n",
    "    for _ in lst:\n",
    "        if _ not in hi:\n",
    "            hi.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 5, 6, 8, 11, 15, 17, 41, 42, 45, 46, 47, 49, 50, 53, 54, 55, 56, 57, 59, 60, 63, 65, 68, 71, 73, 75, 77, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 97, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 122, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 253, 254, 257, 258, 259, 264, 266, 267, 268, 269, 270, 271, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 315, 316, 317, 318, 319, 320, 321, 322, 325, 326, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 354, 355, 356, 357, 358, 359, 360, 361, 363, 366, 367, 380, 382, 388, 389, 399, 401, 404, 405, 409, 412, 413, 417, 418, 423, 429, 432, 435, 440, 442, 446, 457, 463, 478, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5337, 5340, 5341, 5342, 5343, 5345, 5346, 5347, 5350, 5351, 5353, 5354, 5356, 5357, 5358, 5359, 5362, 5363, 5364, 5365, 5366, 5368, 5369, 5370, 5372, 5374, 5377, 5378, 5379, 5380, 5381, 5382, 5384, 5385, 5386, 5388, 5389, 5390, 5391, 5392, 5393, 5394, 5395, 5396, 5397, 5398, 5399, 5400, 5401, 5403, 5406, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5424, 5425, 5427, 5428, 5429, 5430, 5431, 5432, 5434, 5435, 5436, 5437, 5438, 5439, 5440, 5441, 5442, 5443, 5444, 5445, 5446, 5448, 5449, 5450, 5451, 5452, 5453, 5454, 5455, 5456, 5457, 5458, 5459, 5460, 5461, 5462, 5463, 5464, 5465, 5466, 5467, 5468, 5469, 5471, 5472, 5473, 5474, 5475, 5476, 5477, 5478, 5479, 5480, 5481, 5482, 5483, 5485, 5486, 5488, 5489, 5490, 5491, 5492, 5493, 5494, 5495, 5496, 5497, 5499, 5501, 5502, 5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5524, 5528, 5529, 5533, 5534, 5535, 5536, 5537, 5538, 5539, 5540, 5542, 5543, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5558, 5559, 5561, 5563, 5564, 5565, 5566, 5567, 5569, 5570, 5571, 5572, 5574, 5575, 5576, 5577, 5578, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5587, 5590, 5591, 5592, 5593, 5594, 5596, 5598, 5600, 5602, 5605, 5607, 5611, 5612, 5615, 5616, 5617, 5619, 5621, 5622, 5624, 5625, 5626, 5627, 5628, 5630, 5631, 5632, 5636, 5637, 5640, 5642, 5643, 5644, 5645, 5648, 5649, 5650, 5655, 5658, 5659, 5660, 5661, 5662, 5663, 5664, 5665, 5666, 5667, 5668, 5669, 5670, 5673, 5674, 5675, 5677, 5678, 5689, 5690, 5691, 5693, 5694, 5696, 5697, 5698, 5701, 5702, 5704, 5708, 5712, 5724, 5725, 5726, 5727, 5729, 5730, 5731, 5732, 5733, 5734, 5735, 5736, 5737, 5739, 5741, 5743, 5745, 5748, 5751, 5753, 5754, 5755, 5758, 5760, 5761, 5762, 5763, 5765, 5766, 5767, 5768, 5770, 5771, 5772, 5773, 5774, 5775, 5777, 5778, 5781, 5782, 5783, 5784, 5785, 5787, 5788, 5789, 5790, 5791, 5792, 5793, 5794, 5795, 5796, 5797, 5798, 5799, 5800, 5801, 5802, 5803, 5804, 5805, 5806, 5807, 5808, 5809, 5810, 5811, 5812, 5814, 5815, 5816, 5818, 5819, 5820, 5821, 5822, 5823, 5824, 5825, 5826, 5827, 5828, 5829, 5830, 5833, 5837, 5838, 5839, 5840, 5841, 5842, 5843, 5845, 5846, 5848, 5849, 5850, 5855, 5859, 5860, 5861, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5870, 5872, 5873, 5874, 5875, 5880, 5886, 5890, 5893, 5900, 5907, 5908, 5910, 5913, 5916, 5917, 5918, 5920, 5922, 5923, 5924, 5926, 5927, 5928, 5929, 5930, 5931, 5940, 5943, 5944, 5945, 5946, 5947, 5948, 5949, 5950, 5951, 5952, 5953, 5954, 5957, 5959, 5961, 5962, 5963, 5964, 5965, 5970, 5972, 5976, 5980, 5981, 5983, 5985, 5986, 5988, 5991, 5994, 5995, 5996, 5997, 5998, 6001, 6003, 6004, 6005, 6006, 6007, 6008, 6009, 6010, 6011, 6012, 6013, 6014, 6015, 6016, 6018, 6019, 6022, 6023, 6026, 6028, 6029, 6030, 6033, 6035, 6037, 6038, 6040, 6041, 6044, 6050, 6051, 6052, 6055, 6059, 6060, 6061, 6062, 6063, 6069, 6079, 6080, 6081, 6082, 6083, 6084, 6085, 6086, 6087, 6090, 6091, 6094, 6095, 6097, 6099, 6100, 6104, 6107, 6109, 6113, 6116, 6122, 6123, 6124, 6126, 6127, 6128, 6130, 6131, 6132, 6133, 6134, 6135, 6136, 6137, 6139, 6140, 6141, 6142, 6143, 6144, 6146, 6147, 6148, 6149, 6150, 6152, 6153, 6156, 6157, 6158, 6160, 6161, 6162, 6164, 6165, 6166, 6167, 6168, 6169, 6170, 6171, 6172, 6173, 6175, 6176, 6178, 6180, 6181, 6182, 6183, 6184, 6186, 6188, 6189, 6190, 6191, 6197, 6198, 6199, 6201, 6202, 6204, 6210, 6212, 6213, 6214, 6215, 6216, 6217, 6218, 6219, 6221, 6222, 6224, 6227, 6228, 6230, 6231, 6232, 6233, 6234, 6236, 6237, 6238, 6239, 6240, 6241, 6243, 6247, 6248, 6249, 6250, 6252, 6255, 6256, 6257, 6258, 6259, 6260, 6261, 6262, 6263, 6264, 6265, 6266, 6267, 6268, 6270, 6271, 6272, 6273, 6274, 6275, 6276, 6278, 6279, 6280, 6281, 6282, 6283, 6284, 6285, 6286, 6287, 6288, 6295, 6296, 6297, 6298, 6299, 6300, 6301, 6302, 6303, 6304, 6305, 6306, 6307, 6308, 6309, 6310, 6311, 6312, 6313, 6314, 6315, 6316, 6317, 6319, 6322, 6323, 6324, 6326, 6328, 6330, 6332, 6333, 6334, 6335, 6336, 6338, 6339, 6341, 6343, 6344, 6345, 6347, 6348, 6349, 6350, 6353, 6354, 6355, 6356, 6357, 6361, 6362, 6363, 6364, 6365, 6366, 6367, 6371, 6372, 6374, 6375, 6376, 6377, 6378, 6379, 6380, 6381, 6382, 6383, 6384, 6385, 6386, 6387, 6388, 6389, 6391, 6392, 6397, 6398, 6399, 6401, 6402, 6404, 6405, 6406, 6407, 6408, 6409, 6410, 6411, 6412, 6413, 6414, 6415, 6416, 6418, 6421, 6422, 6424, 6425, 6426, 6427, 6428, 6429, 6430, 6431, 6433, 6434, 6435, 6439, 6440, 6441, 6444, 6445, 6446, 6447, 6448, 6449, 6450, 6451, 6452, 6454, 6455, 6456, 6457, 6458, 6460, 6461, 6463, 6464, 6465, 6467, 6470, 6473, 6474, 6476, 6477, 6480, 6484, 6485, 6486, 6487, 6492, 6493, 6494, 6495, 6496, 6498, 6499, 6501, 6502, 6503, 6504, 6505, 6506, 6508, 6509, 6510, 6511, 6513, 6514, 6515, 6516, 6517, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6527, 6528, 6529, 6530, 6532, 6533, 6534, 6536, 6537, 6538, 6541, 6542, 6543, 6544, 6545, 6546, 6549, 6550, 6552, 6553, 6554, 6555, 6556, 6557, 6558, 6559, 6560, 6561, 6562, 6566, 6567, 6568, 6569, 6573, 6574, 6578, 6579, 6580, 6581, 6582, 6583, 6584, 6587, 6588, 6589, 6592, 6593, 6596, 6597, 6599, 6602, 6605, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6614, 6615, 6616, 6617, 6618, 6619, 6620, 6621, 6622, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6632, 6634, 6635, 6636, 6637, 6638, 6639, 6640, 6641, 6643, 6644, 6645, 6646, 6650, 6651, 6653, 6654, 6657, 6658, 6659, 6660, 6663, 6664, 6669, 6673, 6678, 6681, 6683, 6684, 6685, 6686, 6687, 6689, 6690, 6692, 6693, 6694, 6695, 6697, 6699, 6700, 6701, 6703, 6705, 6706, 6708, 6709, 6710, 6712, 6713, 6715, 6716, 6718, 6719, 6722, 6728, 6729, 6730, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6749, 6750, 6751, 6752, 6753, 6754, 6756, 6759, 6760, 6762, 6764, 6770, 6771, 6773, 6777, 6778, 6779, 6781, 6785, 6792, 6793, 6794, 6795, 6797, 6798, 6799, 6800, 6801, 6803, 6804, 6805, 6806, 6807, 6808, 6809, 6810, 6811, 6812, 6813, 6814, 6816, 6817, 6818, 6819, 6820, 6821, 6823, 6824, 6826, 6828, 6831, 6832, 6834, 6835, 6837, 6838, 6840, 6842, 6844, 6845, 6846, 6847, 6848, 6850, 6852, 6853, 6854, 6855, 6856, 6857, 6858, 6861, 6865, 6867, 6868, 6869, 6870, 6873, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6883, 6886, 6887, 6888, 6889, 6890, 6891, 6892, 6893, 6894, 6895, 6896, 6897, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6908, 6909, 6910, 6911, 6912, 6913, 6916, 6917, 6918, 6919, 6920, 6923, 6924, 6925, 6926, 6927, 6928, 6929, 6930, 6931, 6932, 6933, 6934, 6936, 6938, 6939, 6940, 6943, 6946, 6947, 6951, 6952, 6953, 6954, 6955, 6956, 6957, 6958, 6959, 6960, 6963, 6964, 6965, 6966, 6967, 6968, 6969, 6970, 6972, 6973, 6974, 6975, 6976, 6977, 6980, 6981, 6982, 6983, 6984, 6985, 6988, 6992, 6993, 6995, 6996, 6998, 6999, 7000, 7001, 7003, 7004, 7005, 7007, 7010, 7011, 7012, 7013, 7015, 7016, 7018, 7020, 7028, 7030, 7031, 7032, 7038, 7039, 7040, 7041, 7043, 7044, 7046, 7048, 7050, 7052, 7053, 7054, 7056, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7068, 7069, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7086, 7087, 7088, 7089, 7090, 7093, 7095, 7096, 7098, 7099, 7104, 7106, 7107, 7109, 7110, 7114, 7115, 7117, 7118, 7119, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7129, 7130, 7131, 7134, 7135, 7136, 7138, 7140, 7141, 7142, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7157, 7159, 7160, 7161, 7162, 7163, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7174, 7175, 7176, 7177, 7178, 7180, 7181, 7182, 7183, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7207, 7208, 7209, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7225, 7226, 7227, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7237, 7238, 7239, 7242, 7253, 7254, 7255, 7256, 7258, 7259, 7260, 7261, 7262, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7281, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298, 7299, 7300, 7301, 7307, 7309, 7311, 7315, 7316, 7317, 7318, 7320, 7322, 7323, 7326, 7327, 7328, 7329, 7330, 7332, 7333, 7334, 7335, 7337, 7338, 7339, 7340, 7342, 7343, 7344, 7346, 7347, 7348, 7349, 7350, 7351, 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7359, 7360, 7361, 7362, 7363, 7365, 7366, 7367, 7368, 7369, 7375, 7376, 7378, 7380, 7382, 7383, 7384, 7388, 7389, 7390, 7391, 7392, 7394, 7398, 7399, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7410, 7414, 7416, 7417, 7418, 7419, 7420, 7421, 7422, 7424, 7425, 7426, 7427, 7428, 7430, 7431, 7432, 7433, 7434, 7436, 7437, 7438, 7439, 7440, 7441, 7446, 7447, 7448, 7449, 7452, 7453, 7454, 7457, 7458, 7459, 7460, 7461, 7462, 7463, 7464, 7465, 7466, 7467, 7469, 7470, 7472, 7475, 7476, 7477, 7479, 7480, 7482, 7483, 7484, 7486, 7490, 7491, 7492, 7495, 7496, 7497, 7499, 7500, 7501, 7503, 7504, 7505, 7508, 7509, 7510, 7511, 7515, 7519, 7520, 7521, 7525, 7526, 7530, 7531, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7546, 7548, 7551, 7552, 7554, 7557, 7560, 7561, 7562, 7565, 7569, 7570, 7573, 7580, 7581, 7584, 7585, 7586, 7587, 7589, 7590, 7591, 7594, 7595, 7597, 7598, 7600, 7601, 7605, 7608, 7609, 7610, 7611, 7613, 7617, 7618, 7619, 7621, 7622, 7623, 7628, 7629, 7630, 7631, 7632, 7633, 7634, 7635, 7636, 7637, 7638, 7639, 7640, 7641, 7642, 7643, 7644, 7645, 7646, 7647, 7650, 7654, 7657, 7659, 7660, 7661, 7662, 7663, 7664, 7665, 7667, 7670, 7671, 7673, 7674, 7676, 7678, 7679, 7680, 7681, 7682, 7683, 7685, 7688, 7689, 7690, 7692, 7693, 7695, 7696, 7697, 7698, 7699, 7700, 7701, 7705, 7707, 7708, 7709, 7711, 7712, 7713, 7714, 7716, 7717, 7719, 7720, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7733, 7734, 7735, 7736, 7737, 7738, 7739, 7741, 7743, 7744, 7745, 7746, 7747, 7748, 7749, 7750, 7751, 7754, 7755, 7756, 7757, 7758, 7759, 7761, 7762, 7763, 7764, 7765, 7767, 7768, 7771, 7773, 7775, 7776, 7779, 7780, 7781, 7782, 7788, 7789, 7792, 7793, 7796, 7815, 7816, 7818, 7820, 7821, 7822, 7823, 7824, 7825, 7826, 7827, 7828, 7829, 7830, 7831, 7835, 7836, 7837, 7838, 7842, 7844, 7845, 7846, 7847, 7848, 7849, 7851, 7859, 7861, 7862, 7869, 7873, 7881, 7882, 7883, 7884, 7885, 7886, 7887, 7888, 7890, 7891, 7894, 7895, 7899, 7901, 7902, 7903, 7904, 7905, 7906, 7907, 7908, 7911, 7912, 7913, 7914, 7915, 7916, 7917, 7918, 7921, 7922, 7924, 7925, 7928, 7930, 7931, 7932, 7933, 7935, 7936, 7937, 7939, 7940, 7941, 7943, 7944, 7945, 7946, 7947, 7948, 7949, 7951, 7952, 7953, 7954, 7957, 7960, 7962, 7964, 7965, 7966, 7967, 7968, 7969, 7971, 7979, 7980, 7983, 7985, 7988, 7989, 7992, 7993, 7994, 7996, 7998, 8000, 8001}\n"
     ]
    }
   ],
   "source": [
    "print(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi2 = set()\n",
    "for lst in bodytok:\n",
    "    for _ in lst:\n",
    "        if _ not in hi2:\n",
    "            hi2.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 65, 68, 71, 73, 75, 77, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 97, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 122, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 369, 371, 372, 373, 374, 376, 377, 380, 382, 383, 385, 386, 387, 388, 389, 392, 394, 396, 397, 398, 399, 400, 401, 404, 405, 409, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 426, 427, 429, 430, 432, 433, 435, 437, 440, 441, 442, 446, 448, 449, 450, 451, 453, 455, 456, 457, 458, 459, 460, 461, 463, 478, 511, 5241, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5337, 5338, 5340, 5341, 5342, 5343, 5345, 5346, 5347, 5350, 5351, 5352, 5353, 5354, 5355, 5356, 5357, 5358, 5359, 5362, 5363, 5364, 5365, 5366, 5368, 5369, 5370, 5372, 5374, 5377, 5378, 5379, 5380, 5381, 5382, 5384, 5385, 5386, 5388, 5389, 5390, 5391, 5392, 5393, 5394, 5395, 5396, 5397, 5398, 5399, 5400, 5401, 5402, 5403, 5404, 5406, 5407, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5424, 5425, 5427, 5428, 5429, 5430, 5431, 5432, 5434, 5435, 5436, 5437, 5438, 5439, 5440, 5441, 5442, 5443, 5444, 5445, 5446, 5448, 5449, 5450, 5451, 5452, 5453, 5454, 5455, 5456, 5457, 5458, 5459, 5460, 5461, 5462, 5463, 5464, 5465, 5466, 5467, 5468, 5469, 5471, 5472, 5473, 5474, 5475, 5476, 5477, 5478, 5479, 5480, 5481, 5482, 5483, 5485, 5486, 5488, 5489, 5490, 5491, 5492, 5493, 5494, 5495, 5496, 5497, 5499, 5501, 5502, 5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5523, 5524, 5528, 5529, 5530, 5531, 5533, 5534, 5535, 5536, 5537, 5538, 5539, 5542, 5543, 5544, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5558, 5559, 5560, 5561, 5562, 5563, 5564, 5565, 5566, 5567, 5569, 5570, 5571, 5572, 5574, 5575, 5576, 5577, 5578, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5587, 5588, 5590, 5591, 5592, 5593, 5594, 5595, 5596, 5598, 5600, 5602, 5605, 5607, 5609, 5611, 5612, 5615, 5616, 5617, 5619, 5620, 5621, 5622, 5624, 5625, 5626, 5627, 5628, 5630, 5631, 5632, 5636, 5637, 5639, 5640, 5642, 5643, 5644, 5645, 5647, 5648, 5649, 5650, 5651, 5655, 5658, 5659, 5660, 5661, 5662, 5663, 5664, 5665, 5666, 5667, 5668, 5669, 5670, 5672, 5673, 5674, 5675, 5677, 5678, 5680, 5687, 5688, 5689, 5690, 5691, 5693, 5694, 5696, 5697, 5698, 5699, 5701, 5702, 5703, 5704, 5705, 5708, 5710, 5712, 5718, 5724, 5725, 5726, 5727, 5729, 5730, 5731, 5732, 5733, 5734, 5735, 5736, 5737, 5739, 5741, 5742, 5743, 5745, 5748, 5751, 5753, 5754, 5755, 5758, 5759, 5760, 5761, 5762, 5763, 5765, 5766, 5767, 5768, 5770, 5771, 5772, 5773, 5774, 5775, 5777, 5778, 5781, 5782, 5783, 5784, 5785, 5787, 5788, 5789, 5790, 5791, 5792, 5793, 5794, 5795, 5796, 5797, 5798, 5799, 5800, 5801, 5802, 5803, 5804, 5805, 5806, 5807, 5808, 5809, 5810, 5811, 5812, 5814, 5815, 5816, 5817, 5818, 5819, 5820, 5821, 5822, 5823, 5824, 5825, 5826, 5827, 5828, 5829, 5830, 5831, 5833, 5834, 5837, 5838, 5839, 5840, 5841, 5842, 5843, 5845, 5846, 5847, 5848, 5849, 5850, 5853, 5855, 5859, 5860, 5861, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5869, 5870, 5872, 5873, 5874, 5875, 5876, 5880, 5882, 5886, 5890, 5892, 5893, 5896, 5900, 5902, 5903, 5907, 5908, 5910, 5913, 5916, 5917, 5918, 5920, 5922, 5923, 5924, 5925, 5926, 5927, 5928, 5929, 5930, 5931, 5934, 5940, 5943, 5944, 5945, 5946, 5947, 5948, 5949, 5950, 5951, 5952, 5953, 5954, 5957, 5959, 5960, 5961, 5962, 5963, 5964, 5965, 5966, 5968, 5970, 5972, 5976, 5980, 5981, 5983, 5985, 5986, 5988, 5991, 5994, 5995, 5996, 5997, 5998, 6001, 6003, 6004, 6005, 6006, 6007, 6008, 6009, 6010, 6011, 6012, 6013, 6014, 6015, 6016, 6017, 6018, 6019, 6022, 6023, 6024, 6025, 6026, 6028, 6029, 6030, 6032, 6033, 6035, 6037, 6038, 6040, 6041, 6043, 6048, 6050, 6051, 6052, 6053, 6054, 6055, 6059, 6060, 6061, 6062, 6063, 6064, 6067, 6069, 6079, 6080, 6081, 6082, 6083, 6084, 6085, 6086, 6087, 6090, 6091, 6094, 6095, 6097, 6098, 6099, 6100, 6104, 6106, 6107, 6109, 6113, 6116, 6120, 6122, 6123, 6124, 6126, 6127, 6128, 6129, 6130, 6131, 6132, 6133, 6134, 6135, 6136, 6137, 6139, 6140, 6141, 6142, 6143, 6144, 6145, 6146, 6147, 6148, 6149, 6150, 6152, 6153, 6156, 6157, 6158, 6160, 6161, 6162, 6164, 6165, 6166, 6167, 6168, 6169, 6170, 6171, 6172, 6173, 6175, 6176, 6177, 6178, 6180, 6181, 6182, 6183, 6184, 6186, 6188, 6189, 6190, 6191, 6197, 6198, 6199, 6201, 6202, 6204, 6210, 6212, 6213, 6214, 6215, 6216, 6217, 6218, 6219, 6221, 6222, 6224, 6225, 6227, 6228, 6230, 6231, 6232, 6233, 6234, 6236, 6237, 6238, 6239, 6240, 6241, 6243, 6247, 6248, 6249, 6250, 6251, 6252, 6253, 6255, 6256, 6257, 6258, 6259, 6260, 6261, 6262, 6263, 6264, 6265, 6266, 6267, 6268, 6270, 6271, 6272, 6273, 6274, 6275, 6276, 6277, 6278, 6279, 6280, 6281, 6282, 6283, 6284, 6285, 6286, 6287, 6288, 6291, 6292, 6295, 6296, 6297, 6298, 6299, 6300, 6301, 6302, 6303, 6304, 6305, 6306, 6307, 6308, 6309, 6310, 6311, 6312, 6313, 6314, 6315, 6316, 6317, 6318, 6319, 6320, 6321, 6322, 6323, 6324, 6326, 6328, 6330, 6332, 6333, 6334, 6335, 6336, 6338, 6339, 6341, 6343, 6344, 6345, 6346, 6347, 6348, 6349, 6350, 6351, 6353, 6354, 6355, 6356, 6357, 6359, 6361, 6362, 6363, 6364, 6365, 6366, 6367, 6368, 6370, 6371, 6372, 6373, 6374, 6375, 6376, 6377, 6378, 6379, 6380, 6381, 6382, 6383, 6384, 6385, 6386, 6387, 6388, 6389, 6391, 6392, 6395, 6396, 6397, 6398, 6399, 6401, 6402, 6404, 6405, 6406, 6407, 6408, 6409, 6410, 6411, 6412, 6413, 6414, 6415, 6416, 6417, 6418, 6421, 6422, 6424, 6425, 6426, 6427, 6428, 6429, 6430, 6431, 6432, 6433, 6434, 6435, 6436, 6439, 6440, 6441, 6442, 6444, 6445, 6446, 6447, 6448, 6449, 6450, 6451, 6452, 6453, 6454, 6455, 6456, 6457, 6458, 6459, 6460, 6461, 6463, 6464, 6465, 6467, 6470, 6473, 6474, 6476, 6477, 6480, 6481, 6484, 6485, 6486, 6487, 6492, 6493, 6494, 6495, 6496, 6498, 6499, 6501, 6502, 6503, 6504, 6505, 6506, 6508, 6509, 6510, 6511, 6512, 6513, 6514, 6515, 6516, 6517, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6527, 6528, 6529, 6530, 6532, 6533, 6534, 6536, 6537, 6538, 6541, 6542, 6543, 6544, 6545, 6546, 6548, 6549, 6550, 6552, 6553, 6554, 6555, 6556, 6557, 6558, 6559, 6560, 6561, 6562, 6563, 6566, 6567, 6568, 6569, 6573, 6574, 6575, 6578, 6579, 6580, 6581, 6582, 6583, 6584, 6586, 6587, 6588, 6589, 6591, 6592, 6593, 6595, 6596, 6597, 6598, 6599, 6600, 6602, 6605, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6619, 6620, 6621, 6622, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6632, 6634, 6635, 6636, 6637, 6638, 6639, 6640, 6641, 6642, 6643, 6644, 6645, 6646, 6650, 6651, 6653, 6654, 6657, 6658, 6659, 6660, 6663, 6664, 6669, 6673, 6678, 6679, 6681, 6683, 6684, 6685, 6686, 6687, 6688, 6689, 6690, 6692, 6693, 6694, 6695, 6697, 6699, 6700, 6701, 6703, 6705, 6706, 6708, 6709, 6710, 6712, 6713, 6715, 6716, 6718, 6719, 6722, 6728, 6729, 6730, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6749, 6750, 6751, 6752, 6753, 6754, 6756, 6759, 6760, 6762, 6763, 6764, 6770, 6771, 6773, 6774, 6777, 6778, 6779, 6781, 6784, 6785, 6792, 6793, 6794, 6795, 6796, 6797, 6798, 6799, 6800, 6801, 6802, 6803, 6804, 6805, 6806, 6807, 6808, 6809, 6810, 6811, 6812, 6813, 6814, 6816, 6817, 6818, 6819, 6820, 6821, 6822, 6823, 6824, 6828, 6831, 6832, 6833, 6834, 6835, 6837, 6838, 6840, 6841, 6842, 6843, 6844, 6845, 6846, 6847, 6848, 6850, 6852, 6853, 6854, 6855, 6856, 6857, 6858, 6859, 6861, 6865, 6867, 6868, 6869, 6870, 6871, 6873, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6883, 6884, 6886, 6887, 6888, 6889, 6890, 6891, 6892, 6893, 6894, 6895, 6896, 6897, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6908, 6909, 6910, 6911, 6912, 6913, 6914, 6915, 6916, 6917, 6918, 6919, 6920, 6923, 6924, 6925, 6926, 6927, 6928, 6929, 6930, 6931, 6932, 6933, 6934, 6936, 6938, 6939, 6940, 6943, 6944, 6946, 6947, 6950, 6951, 6952, 6953, 6954, 6955, 6956, 6957, 6958, 6959, 6960, 6961, 6963, 6964, 6965, 6966, 6967, 6968, 6969, 6970, 6972, 6973, 6974, 6975, 6976, 6977, 6978, 6980, 6981, 6982, 6983, 6984, 6985, 6986, 6988, 6990, 6992, 6993, 6994, 6995, 6996, 6998, 6999, 7000, 7001, 7002, 7003, 7004, 7005, 7007, 7010, 7011, 7012, 7013, 7015, 7016, 7018, 7020, 7027, 7028, 7030, 7031, 7032, 7037, 7038, 7039, 7040, 7041, 7043, 7044, 7046, 7048, 7050, 7052, 7053, 7054, 7056, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7068, 7069, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7086, 7087, 7088, 7089, 7090, 7093, 7094, 7095, 7096, 7098, 7099, 7101, 7102, 7104, 7106, 7107, 7109, 7110, 7114, 7115, 7117, 7118, 7119, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7129, 7130, 7131, 7134, 7135, 7136, 7138, 7140, 7141, 7142, 7144, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7157, 7159, 7160, 7161, 7162, 7163, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7174, 7175, 7176, 7177, 7178, 7180, 7181, 7182, 7183, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7207, 7208, 7209, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7225, 7226, 7227, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7237, 7238, 7239, 7241, 7242, 7244, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298, 7299, 7300, 7301, 7306, 7307, 7310, 7311, 7314, 7315, 7316, 7317, 7318, 7319, 7320, 7321, 7322, 7323, 7325, 7326, 7327, 7328, 7329, 7330, 7332, 7333, 7334, 7335, 7337, 7338, 7339, 7340, 7342, 7343, 7344, 7346, 7347, 7348, 7349, 7350, 7351, 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7359, 7360, 7361, 7362, 7363, 7365, 7366, 7367, 7368, 7369, 7372, 7375, 7376, 7378, 7380, 7382, 7383, 7384, 7388, 7389, 7390, 7391, 7392, 7393, 7394, 7395, 7398, 7399, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7410, 7414, 7415, 7416, 7417, 7418, 7419, 7420, 7421, 7422, 7423, 7424, 7425, 7426, 7427, 7428, 7429, 7430, 7431, 7432, 7433, 7434, 7436, 7437, 7438, 7439, 7440, 7441, 7446, 7447, 7448, 7449, 7452, 7453, 7454, 7457, 7458, 7459, 7460, 7461, 7462, 7463, 7464, 7465, 7466, 7467, 7468, 7469, 7470, 7472, 7475, 7476, 7477, 7478, 7479, 7480, 7482, 7483, 7484, 7486, 7488, 7489, 7491, 7492, 7495, 7496, 7497, 7499, 7500, 7501, 7502, 7503, 7504, 7505, 7508, 7509, 7510, 7511, 7512, 7514, 7515, 7518, 7519, 7520, 7521, 7523, 7524, 7525, 7526, 7529, 7530, 7531, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7544, 7546, 7547, 7548, 7550, 7551, 7552, 7553, 7554, 7555, 7557, 7560, 7561, 7562, 7563, 7565, 7566, 7569, 7570, 7573, 7575, 7576, 7578, 7580, 7581, 7583, 7584, 7585, 7586, 7587, 7589, 7590, 7591, 7592, 7594, 7595, 7597, 7598, 7599, 7600, 7601, 7605, 7608, 7609, 7610, 7611, 7613, 7617, 7618, 7619, 7620, 7621, 7622, 7623, 7624, 7628, 7629, 7630, 7631, 7632, 7633, 7634, 7635, 7636, 7637, 7638, 7639, 7640, 7641, 7642, 7643, 7644, 7645, 7646, 7647, 7649, 7650, 7652, 7654, 7659, 7660, 7661, 7662, 7663, 7664, 7665, 7667, 7670, 7671, 7673, 7674, 7675, 7676, 7677, 7678, 7679, 7680, 7682, 7683, 7684, 7685, 7688, 7689, 7690, 7692, 7693, 7695, 7696, 7697, 7698, 7699, 7700, 7701, 7705, 7706, 7707, 7708, 7709, 7711, 7712, 7713, 7714, 7716, 7717, 7718, 7719, 7720, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7732, 7733, 7734, 7735, 7736, 7737, 7738, 7739, 7740, 7741, 7743, 7744, 7745, 7746, 7747, 7748, 7749, 7750, 7751, 7753, 7754, 7755, 7756, 7757, 7758, 7759, 7761, 7762, 7763, 7764, 7765, 7767, 7768, 7769, 7770, 7771, 7772, 7773, 7774, 7775, 7776, 7779, 7780, 7781, 7782, 7785, 7788, 7789, 7792, 7793, 7796, 7797, 7798, 7806, 7808, 7816, 7817, 7818, 7820, 7821, 7822, 7823, 7824, 7825, 7826, 7827, 7828, 7829, 7830, 7831, 7833, 7835, 7836, 7837, 7838, 7842, 7844, 7845, 7846, 7847, 7848, 7849, 7850, 7851, 7853, 7859, 7861, 7862, 7869, 7873, 7881, 7882, 7883, 7884, 7885, 7886, 7887, 7888, 7890, 7891, 7893, 7894, 7895, 7899, 7901, 7902, 7903, 7904, 7905, 7906, 7907, 7908, 7909, 7910, 7911, 7912, 7913, 7914, 7915, 7916, 7917, 7918, 7921, 7922, 7924, 7925, 7927, 7928, 7930, 7931, 7932, 7933, 7935, 7936, 7937, 7938, 7939, 7940, 7941, 7943, 7944, 7945, 7946, 7947, 7948, 7949, 7951, 7952, 7953, 7954, 7957, 7960, 7962, 7964, 7965, 7966, 7967, 7968, 7969, 7970, 7971, 7975, 7979, 7980, 7982, 7983, 7985, 7987, 7988, 7989, 7992, 7993, 7994, 7996, 7998, 8000, 8001}\n"
     ]
    }
   ],
   "source": [
    "print(hi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초반에는 sos를 8002, eos를 8003으로 뒀었다. 그러나 추후 임베딩 시 해당 해당 인덱스를 인식못하는 에러가 발생했다 . 따라서 둘 다에 존재하지 않는 2,3에 sos,eos를 둬도 될것같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sos=2, eos=3  \n",
    "unknown = 0  \n",
    "padded part = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarytok = []\n",
    "for _ in smorphs:\n",
    "    el_id = tok.convert_tokens_to_ids(_)\n",
    "    el_id[0] = 2 #sos\n",
    "    el_id[-1] = 3 #eos\n",
    "    if(len(el_id)<200):\n",
    "        new = el_id+[1]*(200-len(el_id)) #padded part = 1\n",
    "    elif(len(el_id)>200):\n",
    "        new = el_id[:200]\n",
    "        new[-1] = 3 #eos\n",
    "    summarytok.append(new)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[2, 0, 0, 0, 147, 0, 0, 5821, 0, 0, 0, 0, 0, 7782, 8, 5439, 0, 7782, 6888, 5585, 0, 5760, 0, 6556, 0, 5511, 6903, 0, 0, 0, 0, 6903, 0, 0, 7096, 0, 6210, 0, 0, 0, 7157, 7096, 0, 6157, 0, 5760, 0, 6544, 5886, 0, 0, 7088, 0, 0, 6888, 54, 5585, 0, 0, 5760, 8, 5725, 7207, 5821, 0, 0, 0, 5516, 0, 0, 0, 6903, 0, 7088, 0, 7782, 0, 0, 7096, 0, 5330, 5439, 0, 8, 0, 0, 6484, 0, 0, 5859, 5507, 0, 0, 6903, 0, 6855, 7782, 0, 8, 5439, 0, 7782, 6888, 54, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(summarytok[1]))\n",
    "print(summarytok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 6634, 7096, 0, 0, 0, 0, 0, 0, 0, 0, 7095, 0, 0, 5477, 0, 0, 15, 0, 0, 0, 7088, 7945, 7782, 0, 6888, 0, 7086, 0, 0, 0, 7096, 5788, 0, 15, 6005, 0, 7095, 0, 0, 6896, 0, 7095, 0, 7096, 0, 0, 0, 5886, 0, 0, 7088, 0, 7096, 7295, 0, 6116, 0, 8, 0, 5886, 0, 0, 6896, 0, 0, 7289, 6896, 0, 0, 0, 7096, 0, 5886, 0, 6896, 0, 7788, 0, 6421, 7157, 0, 0, 6645, 7088, 0, 6855, 0, 7096, 0, 0, 6116, 7945, 7782, 0, 7088, 0, 7788, 8, 5439, 6300, 7782, 6888, 54, 0, 7086, 8, 0, 6366, 0, 0, 0, 7086, 6867, 6896, 5454, 5886, 0, 0, 7096, 0, 15, 0, 6271, 0, 0, 15, 7096, 0, 15, 7903, 0, 5477, 0, 15, 7096, 6889, 0, 0, 5760, 0, 0, 0, 6116, 0, 6896, 7012, 7782, 6855, 15, 6258, 0, 0, 15, 0, 6016, 0, 7078, 0, 6356, 0, 6116, 0, 7782, 6886, 46, 6165, 7096, 0, 5886, 0, 334, 6116, 0, 7782, 6855, 0, 7088, 0, 7782, 6892, 46, 0, 7012, 0, 0, 5886, 0, 0, 7096, 5561, 3]\n"
     ]
    }
   ],
   "source": [
    "print(len(summarytok[289]))\n",
    "print(summarytok[289])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = set()\n",
    "for lst in summarytok:\n",
    "    for _ in lst:\n",
    "        if _ not in hi:\n",
    "            hi.add(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hi) #num of words in summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = np.array(summarytok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추후 encoder_input / decoder_input 은 embedding을 통해 3Dtensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEGNTH = 512 #for padding\n",
    "NUM_WORDS = 2045 #본문 기사 내 가장 많이 사용된 3000단어?(or 전체 단어수로 할지 미정)\n",
    "VECTOR_SIZE = 768\n",
    "MAX_SUMMARIZATION_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make decoder output (For dense layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "for n,_ in enumerate(hi):\n",
    "    mapping[n] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 5, 5: 6, 6: 8, 7: 11, 8: 15, 9: 17, 10: 41, 11: 42, 12: 45, 13: 46, 14: 47, 15: 49, 16: 50, 17: 53, 18: 54, 19: 55, 20: 56, 21: 57, 22: 59, 23: 60, 24: 63, 25: 65, 26: 68, 27: 71, 28: 73, 29: 75, 30: 77, 31: 79, 32: 81, 33: 82, 34: 83, 35: 85, 36: 86, 37: 87, 38: 88, 39: 89, 40: 90, 41: 91, 42: 93, 43: 97, 44: 101, 45: 104, 46: 105, 47: 106, 48: 107, 49: 108, 50: 109, 51: 110, 52: 111, 53: 112, 54: 113, 55: 114, 56: 115, 57: 116, 58: 119, 59: 122, 60: 124, 61: 127, 62: 128, 63: 129, 64: 130, 65: 131, 66: 132, 67: 133, 68: 134, 69: 135, 70: 136, 71: 137, 72: 138, 73: 139, 74: 140, 75: 141, 76: 142, 77: 144, 78: 145, 79: 146, 80: 147, 81: 148, 82: 149, 83: 150, 84: 151, 85: 152, 86: 153, 87: 154, 88: 155, 89: 157, 90: 160, 91: 161, 92: 162, 93: 163, 94: 164, 95: 165, 96: 166, 97: 167, 98: 168, 99: 169, 100: 170, 101: 171, 102: 172, 103: 175, 104: 176, 105: 177, 106: 178, 107: 179, 108: 180, 109: 181, 110: 182, 111: 183, 112: 184, 113: 185, 114: 186, 115: 187, 116: 188, 117: 190, 118: 191, 119: 192, 120: 193, 121: 194, 122: 195, 123: 196, 124: 197, 125: 198, 126: 199, 127: 200, 128: 201, 129: 202, 130: 205, 131: 207, 132: 208, 133: 209, 134: 210, 135: 211, 136: 212, 137: 213, 138: 214, 139: 215, 140: 216, 141: 217, 142: 218, 143: 219, 144: 222, 145: 223, 146: 224, 147: 225, 148: 226, 149: 227, 150: 228, 151: 229, 152: 230, 153: 231, 154: 232, 155: 233, 156: 234, 157: 237, 158: 238, 159: 239, 160: 240, 161: 241, 162: 242, 163: 243, 164: 244, 165: 245, 166: 246, 167: 247, 168: 248, 169: 249, 170: 253, 171: 254, 172: 257, 173: 258, 174: 259, 175: 264, 176: 266, 177: 267, 178: 268, 179: 269, 180: 270, 181: 271, 182: 274, 183: 275, 184: 276, 185: 277, 186: 278, 187: 279, 188: 280, 189: 282, 190: 283, 191: 284, 192: 285, 193: 286, 194: 287, 195: 288, 196: 289, 197: 290, 198: 291, 199: 292, 200: 293, 201: 294, 202: 295, 203: 296, 204: 298, 205: 299, 206: 300, 207: 301, 208: 303, 209: 304, 210: 305, 211: 306, 212: 307, 213: 308, 214: 309, 215: 310, 216: 311, 217: 312, 218: 313, 219: 315, 220: 316, 221: 317, 222: 318, 223: 319, 224: 320, 225: 321, 226: 322, 227: 325, 228: 326, 229: 328, 230: 329, 231: 331, 232: 332, 233: 333, 234: 334, 235: 335, 236: 336, 237: 337, 238: 338, 239: 339, 240: 340, 241: 341, 242: 342, 243: 343, 244: 344, 245: 345, 246: 346, 247: 347, 248: 348, 249: 349, 250: 351, 251: 354, 252: 355, 253: 356, 254: 357, 255: 358, 256: 359, 257: 360, 258: 361, 259: 363, 260: 366, 261: 367, 262: 380, 263: 382, 264: 388, 265: 389, 266: 399, 267: 401, 268: 404, 269: 405, 270: 409, 271: 412, 272: 413, 273: 417, 274: 418, 275: 423, 276: 429, 277: 432, 278: 435, 279: 440, 280: 442, 281: 446, 282: 457, 283: 463, 284: 478, 285: 5330, 286: 5331, 287: 5332, 288: 5333, 289: 5334, 290: 5335, 291: 5336, 292: 5337, 293: 5340, 294: 5341, 295: 5342, 296: 5343, 297: 5345, 298: 5346, 299: 5347, 300: 5350, 301: 5351, 302: 5353, 303: 5354, 304: 5356, 305: 5357, 306: 5358, 307: 5359, 308: 5362, 309: 5363, 310: 5364, 311: 5365, 312: 5366, 313: 5368, 314: 5369, 315: 5370, 316: 5372, 317: 5374, 318: 5377, 319: 5378, 320: 5379, 321: 5380, 322: 5381, 323: 5382, 324: 5384, 325: 5385, 326: 5386, 327: 5388, 328: 5389, 329: 5390, 330: 5391, 331: 5392, 332: 5393, 333: 5394, 334: 5395, 335: 5396, 336: 5397, 337: 5398, 338: 5399, 339: 5400, 340: 5401, 341: 5403, 342: 5406, 343: 5408, 344: 5409, 345: 5410, 346: 5411, 347: 5412, 348: 5413, 349: 5414, 350: 5415, 351: 5416, 352: 5417, 353: 5418, 354: 5419, 355: 5420, 356: 5424, 357: 5425, 358: 5427, 359: 5428, 360: 5429, 361: 5430, 362: 5431, 363: 5432, 364: 5434, 365: 5435, 366: 5436, 367: 5437, 368: 5438, 369: 5439, 370: 5440, 371: 5441, 372: 5442, 373: 5443, 374: 5444, 375: 5445, 376: 5446, 377: 5448, 378: 5449, 379: 5450, 380: 5451, 381: 5452, 382: 5453, 383: 5454, 384: 5455, 385: 5456, 386: 5457, 387: 5458, 388: 5459, 389: 5460, 390: 5461, 391: 5462, 392: 5463, 393: 5464, 394: 5465, 395: 5466, 396: 5467, 397: 5468, 398: 5469, 399: 5471, 400: 5472, 401: 5473, 402: 5474, 403: 5475, 404: 5476, 405: 5477, 406: 5478, 407: 5479, 408: 5480, 409: 5481, 410: 5482, 411: 5483, 412: 5485, 413: 5486, 414: 5488, 415: 5489, 416: 5490, 417: 5491, 418: 5492, 419: 5493, 420: 5494, 421: 5495, 422: 5496, 423: 5497, 424: 5499, 425: 5501, 426: 5502, 427: 5503, 428: 5504, 429: 5505, 430: 5506, 431: 5507, 432: 5508, 433: 5509, 434: 5510, 435: 5511, 436: 5512, 437: 5513, 438: 5515, 439: 5516, 440: 5517, 441: 5518, 442: 5519, 443: 5520, 444: 5521, 445: 5522, 446: 5524, 447: 5528, 448: 5529, 449: 5533, 450: 5534, 451: 5535, 452: 5536, 453: 5537, 454: 5538, 455: 5539, 456: 5540, 457: 5542, 458: 5543, 459: 5545, 460: 5546, 461: 5547, 462: 5548, 463: 5549, 464: 5550, 465: 5551, 466: 5552, 467: 5553, 468: 5554, 469: 5555, 470: 5556, 471: 5558, 472: 5559, 473: 5561, 474: 5563, 475: 5564, 476: 5565, 477: 5566, 478: 5567, 479: 5569, 480: 5570, 481: 5571, 482: 5572, 483: 5574, 484: 5575, 485: 5576, 486: 5577, 487: 5578, 488: 5580, 489: 5581, 490: 5582, 491: 5583, 492: 5584, 493: 5585, 494: 5586, 495: 5587, 496: 5590, 497: 5591, 498: 5592, 499: 5593, 500: 5594, 501: 5596, 502: 5598, 503: 5600, 504: 5602, 505: 5605, 506: 5607, 507: 5611, 508: 5612, 509: 5615, 510: 5616, 511: 5617, 512: 5619, 513: 5621, 514: 5622, 515: 5624, 516: 5625, 517: 5626, 518: 5627, 519: 5628, 520: 5630, 521: 5631, 522: 5632, 523: 5636, 524: 5637, 525: 5640, 526: 5642, 527: 5643, 528: 5644, 529: 5645, 530: 5648, 531: 5649, 532: 5650, 533: 5655, 534: 5658, 535: 5659, 536: 5660, 537: 5661, 538: 5662, 539: 5663, 540: 5664, 541: 5665, 542: 5666, 543: 5667, 544: 5668, 545: 5669, 546: 5670, 547: 5673, 548: 5674, 549: 5675, 550: 5677, 551: 5678, 552: 5689, 553: 5690, 554: 5691, 555: 5693, 556: 5694, 557: 5696, 558: 5697, 559: 5698, 560: 5701, 561: 5702, 562: 5704, 563: 5708, 564: 5712, 565: 5724, 566: 5725, 567: 5726, 568: 5727, 569: 5729, 570: 5730, 571: 5731, 572: 5732, 573: 5733, 574: 5734, 575: 5735, 576: 5736, 577: 5737, 578: 5739, 579: 5741, 580: 5743, 581: 5745, 582: 5748, 583: 5751, 584: 5753, 585: 5754, 586: 5755, 587: 5758, 588: 5760, 589: 5761, 590: 5762, 591: 5763, 592: 5765, 593: 5766, 594: 5767, 595: 5768, 596: 5770, 597: 5771, 598: 5772, 599: 5773, 600: 5774, 601: 5775, 602: 5777, 603: 5778, 604: 5781, 605: 5782, 606: 5783, 607: 5784, 608: 5785, 609: 5787, 610: 5788, 611: 5789, 612: 5790, 613: 5791, 614: 5792, 615: 5793, 616: 5794, 617: 5795, 618: 5796, 619: 5797, 620: 5798, 621: 5799, 622: 5800, 623: 5801, 624: 5802, 625: 5803, 626: 5804, 627: 5805, 628: 5806, 629: 5807, 630: 5808, 631: 5809, 632: 5810, 633: 5811, 634: 5812, 635: 5814, 636: 5815, 637: 5816, 638: 5818, 639: 5819, 640: 5820, 641: 5821, 642: 5822, 643: 5823, 644: 5824, 645: 5825, 646: 5826, 647: 5827, 648: 5828, 649: 5829, 650: 5830, 651: 5833, 652: 5837, 653: 5838, 654: 5839, 655: 5840, 656: 5841, 657: 5842, 658: 5843, 659: 5845, 660: 5846, 661: 5848, 662: 5849, 663: 5850, 664: 5855, 665: 5859, 666: 5860, 667: 5861, 668: 5862, 669: 5863, 670: 5864, 671: 5865, 672: 5866, 673: 5867, 674: 5868, 675: 5870, 676: 5872, 677: 5873, 678: 5874, 679: 5875, 680: 5880, 681: 5886, 682: 5890, 683: 5893, 684: 5900, 685: 5907, 686: 5908, 687: 5910, 688: 5913, 689: 5916, 690: 5917, 691: 5918, 692: 5920, 693: 5922, 694: 5923, 695: 5924, 696: 5926, 697: 5927, 698: 5928, 699: 5929, 700: 5930, 701: 5931, 702: 5940, 703: 5943, 704: 5944, 705: 5945, 706: 5946, 707: 5947, 708: 5948, 709: 5949, 710: 5950, 711: 5951, 712: 5952, 713: 5953, 714: 5954, 715: 5957, 716: 5959, 717: 5961, 718: 5962, 719: 5963, 720: 5964, 721: 5965, 722: 5970, 723: 5972, 724: 5976, 725: 5980, 726: 5981, 727: 5983, 728: 5985, 729: 5986, 730: 5988, 731: 5991, 732: 5994, 733: 5995, 734: 5996, 735: 5997, 736: 5998, 737: 6001, 738: 6003, 739: 6004, 740: 6005, 741: 6006, 742: 6007, 743: 6008, 744: 6009, 745: 6010, 746: 6011, 747: 6012, 748: 6013, 749: 6014, 750: 6015, 751: 6016, 752: 6018, 753: 6019, 754: 6022, 755: 6023, 756: 6026, 757: 6028, 758: 6029, 759: 6030, 760: 6033, 761: 6035, 762: 6037, 763: 6038, 764: 6040, 765: 6041, 766: 6044, 767: 6050, 768: 6051, 769: 6052, 770: 6055, 771: 6059, 772: 6060, 773: 6061, 774: 6062, 775: 6063, 776: 6069, 777: 6079, 778: 6080, 779: 6081, 780: 6082, 781: 6083, 782: 6084, 783: 6085, 784: 6086, 785: 6087, 786: 6090, 787: 6091, 788: 6094, 789: 6095, 790: 6097, 791: 6099, 792: 6100, 793: 6104, 794: 6107, 795: 6109, 796: 6113, 797: 6116, 798: 6122, 799: 6123, 800: 6124, 801: 6126, 802: 6127, 803: 6128, 804: 6130, 805: 6131, 806: 6132, 807: 6133, 808: 6134, 809: 6135, 810: 6136, 811: 6137, 812: 6139, 813: 6140, 814: 6141, 815: 6142, 816: 6143, 817: 6144, 818: 6146, 819: 6147, 820: 6148, 821: 6149, 822: 6150, 823: 6152, 824: 6153, 825: 6156, 826: 6157, 827: 6158, 828: 6160, 829: 6161, 830: 6162, 831: 6164, 832: 6165, 833: 6166, 834: 6167, 835: 6168, 836: 6169, 837: 6170, 838: 6171, 839: 6172, 840: 6173, 841: 6175, 842: 6176, 843: 6178, 844: 6180, 845: 6181, 846: 6182, 847: 6183, 848: 6184, 849: 6186, 850: 6188, 851: 6189, 852: 6190, 853: 6191, 854: 6197, 855: 6198, 856: 6199, 857: 6201, 858: 6202, 859: 6204, 860: 6210, 861: 6212, 862: 6213, 863: 6214, 864: 6215, 865: 6216, 866: 6217, 867: 6218, 868: 6219, 869: 6221, 870: 6222, 871: 6224, 872: 6227, 873: 6228, 874: 6230, 875: 6231, 876: 6232, 877: 6233, 878: 6234, 879: 6236, 880: 6237, 881: 6238, 882: 6239, 883: 6240, 884: 6241, 885: 6243, 886: 6247, 887: 6248, 888: 6249, 889: 6250, 890: 6252, 891: 6255, 892: 6256, 893: 6257, 894: 6258, 895: 6259, 896: 6260, 897: 6261, 898: 6262, 899: 6263, 900: 6264, 901: 6265, 902: 6266, 903: 6267, 904: 6268, 905: 6270, 906: 6271, 907: 6272, 908: 6273, 909: 6274, 910: 6275, 911: 6276, 912: 6278, 913: 6279, 914: 6280, 915: 6281, 916: 6282, 917: 6283, 918: 6284, 919: 6285, 920: 6286, 921: 6287, 922: 6288, 923: 6295, 924: 6296, 925: 6297, 926: 6298, 927: 6299, 928: 6300, 929: 6301, 930: 6302, 931: 6303, 932: 6304, 933: 6305, 934: 6306, 935: 6307, 936: 6308, 937: 6309, 938: 6310, 939: 6311, 940: 6312, 941: 6313, 942: 6314, 943: 6315, 944: 6316, 945: 6317, 946: 6319, 947: 6322, 948: 6323, 949: 6324, 950: 6326, 951: 6328, 952: 6330, 953: 6332, 954: 6333, 955: 6334, 956: 6335, 957: 6336, 958: 6338, 959: 6339, 960: 6341, 961: 6343, 962: 6344, 963: 6345, 964: 6347, 965: 6348, 966: 6349, 967: 6350, 968: 6353, 969: 6354, 970: 6355, 971: 6356, 972: 6357, 973: 6361, 974: 6362, 975: 6363, 976: 6364, 977: 6365, 978: 6366, 979: 6367, 980: 6371, 981: 6372, 982: 6374, 983: 6375, 984: 6376, 985: 6377, 986: 6378, 987: 6379, 988: 6380, 989: 6381, 990: 6382, 991: 6383, 992: 6384, 993: 6385, 994: 6386, 995: 6387, 996: 6388, 997: 6389, 998: 6391, 999: 6392, 1000: 6397, 1001: 6398, 1002: 6399, 1003: 6401, 1004: 6402, 1005: 6404, 1006: 6405, 1007: 6406, 1008: 6407, 1009: 6408, 1010: 6409, 1011: 6410, 1012: 6411, 1013: 6412, 1014: 6413, 1015: 6414, 1016: 6415, 1017: 6416, 1018: 6418, 1019: 6421, 1020: 6422, 1021: 6424, 1022: 6425, 1023: 6426, 1024: 6427, 1025: 6428, 1026: 6429, 1027: 6430, 1028: 6431, 1029: 6433, 1030: 6434, 1031: 6435, 1032: 6439, 1033: 6440, 1034: 6441, 1035: 6444, 1036: 6445, 1037: 6446, 1038: 6447, 1039: 6448, 1040: 6449, 1041: 6450, 1042: 6451, 1043: 6452, 1044: 6454, 1045: 6455, 1046: 6456, 1047: 6457, 1048: 6458, 1049: 6460, 1050: 6461, 1051: 6463, 1052: 6464, 1053: 6465, 1054: 6467, 1055: 6470, 1056: 6473, 1057: 6474, 1058: 6476, 1059: 6477, 1060: 6480, 1061: 6484, 1062: 6485, 1063: 6486, 1064: 6487, 1065: 6492, 1066: 6493, 1067: 6494, 1068: 6495, 1069: 6496, 1070: 6498, 1071: 6499, 1072: 6501, 1073: 6502, 1074: 6503, 1075: 6504, 1076: 6505, 1077: 6506, 1078: 6508, 1079: 6509, 1080: 6510, 1081: 6511, 1082: 6513, 1083: 6514, 1084: 6515, 1085: 6516, 1086: 6517, 1087: 6518, 1088: 6519, 1089: 6520, 1090: 6521, 1091: 6522, 1092: 6523, 1093: 6524, 1094: 6527, 1095: 6528, 1096: 6529, 1097: 6530, 1098: 6532, 1099: 6533, 1100: 6534, 1101: 6536, 1102: 6537, 1103: 6538, 1104: 6541, 1105: 6542, 1106: 6543, 1107: 6544, 1108: 6545, 1109: 6546, 1110: 6549, 1111: 6550, 1112: 6552, 1113: 6553, 1114: 6554, 1115: 6555, 1116: 6556, 1117: 6557, 1118: 6558, 1119: 6559, 1120: 6560, 1121: 6561, 1122: 6562, 1123: 6566, 1124: 6567, 1125: 6568, 1126: 6569, 1127: 6573, 1128: 6574, 1129: 6578, 1130: 6579, 1131: 6580, 1132: 6581, 1133: 6582, 1134: 6583, 1135: 6584, 1136: 6587, 1137: 6588, 1138: 6589, 1139: 6592, 1140: 6593, 1141: 6596, 1142: 6597, 1143: 6599, 1144: 6602, 1145: 6605, 1146: 6606, 1147: 6607, 1148: 6608, 1149: 6609, 1150: 6610, 1151: 6611, 1152: 6612, 1153: 6614, 1154: 6615, 1155: 6616, 1156: 6617, 1157: 6618, 1158: 6619, 1159: 6620, 1160: 6621, 1161: 6622, 1162: 6624, 1163: 6625, 1164: 6626, 1165: 6627, 1166: 6628, 1167: 6629, 1168: 6630, 1169: 6632, 1170: 6634, 1171: 6635, 1172: 6636, 1173: 6637, 1174: 6638, 1175: 6639, 1176: 6640, 1177: 6641, 1178: 6643, 1179: 6644, 1180: 6645, 1181: 6646, 1182: 6650, 1183: 6651, 1184: 6653, 1185: 6654, 1186: 6657, 1187: 6658, 1188: 6659, 1189: 6660, 1190: 6663, 1191: 6664, 1192: 6669, 1193: 6673, 1194: 6678, 1195: 6681, 1196: 6683, 1197: 6684, 1198: 6685, 1199: 6686, 1200: 6687, 1201: 6689, 1202: 6690, 1203: 6692, 1204: 6693, 1205: 6694, 1206: 6695, 1207: 6697, 1208: 6699, 1209: 6700, 1210: 6701, 1211: 6703, 1212: 6705, 1213: 6706, 1214: 6708, 1215: 6709, 1216: 6710, 1217: 6712, 1218: 6713, 1219: 6715, 1220: 6716, 1221: 6718, 1222: 6719, 1223: 6722, 1224: 6728, 1225: 6729, 1226: 6730, 1227: 6732, 1228: 6733, 1229: 6734, 1230: 6735, 1231: 6736, 1232: 6737, 1233: 6738, 1234: 6739, 1235: 6741, 1236: 6742, 1237: 6743, 1238: 6744, 1239: 6745, 1240: 6746, 1241: 6747, 1242: 6749, 1243: 6750, 1244: 6751, 1245: 6752, 1246: 6753, 1247: 6754, 1248: 6756, 1249: 6759, 1250: 6760, 1251: 6762, 1252: 6764, 1253: 6770, 1254: 6771, 1255: 6773, 1256: 6777, 1257: 6778, 1258: 6779, 1259: 6781, 1260: 6785, 1261: 6792, 1262: 6793, 1263: 6794, 1264: 6795, 1265: 6797, 1266: 6798, 1267: 6799, 1268: 6800, 1269: 6801, 1270: 6803, 1271: 6804, 1272: 6805, 1273: 6806, 1274: 6807, 1275: 6808, 1276: 6809, 1277: 6810, 1278: 6811, 1279: 6812, 1280: 6813, 1281: 6814, 1282: 6816, 1283: 6817, 1284: 6818, 1285: 6819, 1286: 6820, 1287: 6821, 1288: 6823, 1289: 6824, 1290: 6826, 1291: 6828, 1292: 6831, 1293: 6832, 1294: 6834, 1295: 6835, 1296: 6837, 1297: 6838, 1298: 6840, 1299: 6842, 1300: 6844, 1301: 6845, 1302: 6846, 1303: 6847, 1304: 6848, 1305: 6850, 1306: 6852, 1307: 6853, 1308: 6854, 1309: 6855, 1310: 6856, 1311: 6857, 1312: 6858, 1313: 6861, 1314: 6865, 1315: 6867, 1316: 6868, 1317: 6869, 1318: 6870, 1319: 6873, 1320: 6874, 1321: 6875, 1322: 6876, 1323: 6877, 1324: 6878, 1325: 6879, 1326: 6880, 1327: 6881, 1328: 6883, 1329: 6886, 1330: 6887, 1331: 6888, 1332: 6889, 1333: 6890, 1334: 6891, 1335: 6892, 1336: 6893, 1337: 6894, 1338: 6895, 1339: 6896, 1340: 6897, 1341: 6898, 1342: 6899, 1343: 6900, 1344: 6901, 1345: 6902, 1346: 6903, 1347: 6904, 1348: 6905, 1349: 6906, 1350: 6908, 1351: 6909, 1352: 6910, 1353: 6911, 1354: 6912, 1355: 6913, 1356: 6916, 1357: 6917, 1358: 6918, 1359: 6919, 1360: 6920, 1361: 6923, 1362: 6924, 1363: 6925, 1364: 6926, 1365: 6927, 1366: 6928, 1367: 6929, 1368: 6930, 1369: 6931, 1370: 6932, 1371: 6933, 1372: 6934, 1373: 6936, 1374: 6938, 1375: 6939, 1376: 6940, 1377: 6943, 1378: 6946, 1379: 6947, 1380: 6951, 1381: 6952, 1382: 6953, 1383: 6954, 1384: 6955, 1385: 6956, 1386: 6957, 1387: 6958, 1388: 6959, 1389: 6960, 1390: 6963, 1391: 6964, 1392: 6965, 1393: 6966, 1394: 6967, 1395: 6968, 1396: 6969, 1397: 6970, 1398: 6972, 1399: 6973, 1400: 6974, 1401: 6975, 1402: 6976, 1403: 6977, 1404: 6980, 1405: 6981, 1406: 6982, 1407: 6983, 1408: 6984, 1409: 6985, 1410: 6988, 1411: 6992, 1412: 6993, 1413: 6995, 1414: 6996, 1415: 6998, 1416: 6999, 1417: 7000, 1418: 7001, 1419: 7003, 1420: 7004, 1421: 7005, 1422: 7007, 1423: 7010, 1424: 7011, 1425: 7012, 1426: 7013, 1427: 7015, 1428: 7016, 1429: 7018, 1430: 7020, 1431: 7028, 1432: 7030, 1433: 7031, 1434: 7032, 1435: 7038, 1436: 7039, 1437: 7040, 1438: 7041, 1439: 7043, 1440: 7044, 1441: 7046, 1442: 7048, 1443: 7050, 1444: 7052, 1445: 7053, 1446: 7054, 1447: 7056, 1448: 7059, 1449: 7060, 1450: 7061, 1451: 7062, 1452: 7063, 1453: 7064, 1454: 7065, 1455: 7066, 1456: 7068, 1457: 7069, 1458: 7074, 1459: 7075, 1460: 7076, 1461: 7077, 1462: 7078, 1463: 7079, 1464: 7080, 1465: 7081, 1466: 7082, 1467: 7083, 1468: 7084, 1469: 7086, 1470: 7087, 1471: 7088, 1472: 7089, 1473: 7090, 1474: 7093, 1475: 7095, 1476: 7096, 1477: 7098, 1478: 7099, 1479: 7104, 1480: 7106, 1481: 7107, 1482: 7109, 1483: 7110, 1484: 7114, 1485: 7115, 1486: 7117, 1487: 7118, 1488: 7119, 1489: 7121, 1490: 7122, 1491: 7123, 1492: 7124, 1493: 7125, 1494: 7126, 1495: 7127, 1496: 7129, 1497: 7130, 1498: 7131, 1499: 7134, 1500: 7135, 1501: 7136, 1502: 7138, 1503: 7140, 1504: 7141, 1505: 7142, 1506: 7145, 1507: 7146, 1508: 7147, 1509: 7148, 1510: 7149, 1511: 7150, 1512: 7151, 1513: 7157, 1514: 7159, 1515: 7160, 1516: 7161, 1517: 7162, 1518: 7163, 1519: 7166, 1520: 7167, 1521: 7168, 1522: 7169, 1523: 7170, 1524: 7171, 1525: 7172, 1526: 7174, 1527: 7175, 1528: 7176, 1529: 7177, 1530: 7178, 1531: 7180, 1532: 7181, 1533: 7182, 1534: 7183, 1535: 7189, 1536: 7190, 1537: 7191, 1538: 7192, 1539: 7193, 1540: 7194, 1541: 7195, 1542: 7196, 1543: 7197, 1544: 7198, 1545: 7199, 1546: 7200, 1547: 7201, 1548: 7202, 1549: 7207, 1550: 7208, 1551: 7209, 1552: 7214, 1553: 7215, 1554: 7216, 1555: 7217, 1556: 7218, 1557: 7219, 1558: 7220, 1559: 7221, 1560: 7225, 1561: 7226, 1562: 7227, 1563: 7229, 1564: 7230, 1565: 7231, 1566: 7232, 1567: 7233, 1568: 7234, 1569: 7235, 1570: 7237, 1571: 7238, 1572: 7239, 1573: 7242, 1574: 7253, 1575: 7254, 1576: 7255, 1577: 7256, 1578: 7258, 1579: 7259, 1580: 7260, 1581: 7261, 1582: 7262, 1583: 7264, 1584: 7265, 1585: 7266, 1586: 7267, 1587: 7268, 1588: 7269, 1589: 7270, 1590: 7271, 1591: 7273, 1592: 7274, 1593: 7275, 1594: 7276, 1595: 7277, 1596: 7278, 1597: 7279, 1598: 7281, 1599: 7283, 1600: 7284, 1601: 7285, 1602: 7286, 1603: 7287, 1604: 7288, 1605: 7289, 1606: 7291, 1607: 7292, 1608: 7293, 1609: 7294, 1610: 7295, 1611: 7296, 1612: 7297, 1613: 7298, 1614: 7299, 1615: 7300, 1616: 7301, 1617: 7307, 1618: 7309, 1619: 7311, 1620: 7315, 1621: 7316, 1622: 7317, 1623: 7318, 1624: 7320, 1625: 7322, 1626: 7323, 1627: 7326, 1628: 7327, 1629: 7328, 1630: 7329, 1631: 7330, 1632: 7332, 1633: 7333, 1634: 7334, 1635: 7335, 1636: 7337, 1637: 7338, 1638: 7339, 1639: 7340, 1640: 7342, 1641: 7343, 1642: 7344, 1643: 7346, 1644: 7347, 1645: 7348, 1646: 7349, 1647: 7350, 1648: 7351, 1649: 7352, 1650: 7353, 1651: 7354, 1652: 7355, 1653: 7356, 1654: 7357, 1655: 7358, 1656: 7359, 1657: 7360, 1658: 7361, 1659: 7362, 1660: 7363, 1661: 7365, 1662: 7366, 1663: 7367, 1664: 7368, 1665: 7369, 1666: 7375, 1667: 7376, 1668: 7378, 1669: 7380, 1670: 7382, 1671: 7383, 1672: 7384, 1673: 7388, 1674: 7389, 1675: 7390, 1676: 7391, 1677: 7392, 1678: 7394, 1679: 7398, 1680: 7399, 1681: 7402, 1682: 7403, 1683: 7404, 1684: 7405, 1685: 7406, 1686: 7407, 1687: 7408, 1688: 7410, 1689: 7414, 1690: 7416, 1691: 7417, 1692: 7418, 1693: 7419, 1694: 7420, 1695: 7421, 1696: 7422, 1697: 7424, 1698: 7425, 1699: 7426, 1700: 7427, 1701: 7428, 1702: 7430, 1703: 7431, 1704: 7432, 1705: 7433, 1706: 7434, 1707: 7436, 1708: 7437, 1709: 7438, 1710: 7439, 1711: 7440, 1712: 7441, 1713: 7446, 1714: 7447, 1715: 7448, 1716: 7449, 1717: 7452, 1718: 7453, 1719: 7454, 1720: 7457, 1721: 7458, 1722: 7459, 1723: 7460, 1724: 7461, 1725: 7462, 1726: 7463, 1727: 7464, 1728: 7465, 1729: 7466, 1730: 7467, 1731: 7469, 1732: 7470, 1733: 7472, 1734: 7475, 1735: 7476, 1736: 7477, 1737: 7479, 1738: 7480, 1739: 7482, 1740: 7483, 1741: 7484, 1742: 7486, 1743: 7490, 1744: 7491, 1745: 7492, 1746: 7495, 1747: 7496, 1748: 7497, 1749: 7499, 1750: 7500, 1751: 7501, 1752: 7503, 1753: 7504, 1754: 7505, 1755: 7508, 1756: 7509, 1757: 7510, 1758: 7511, 1759: 7515, 1760: 7519, 1761: 7520, 1762: 7521, 1763: 7525, 1764: 7526, 1765: 7530, 1766: 7531, 1767: 7533, 1768: 7534, 1769: 7535, 1770: 7536, 1771: 7537, 1772: 7538, 1773: 7539, 1774: 7540, 1775: 7541, 1776: 7542, 1777: 7546, 1778: 7548, 1779: 7551, 1780: 7552, 1781: 7554, 1782: 7557, 1783: 7560, 1784: 7561, 1785: 7562, 1786: 7565, 1787: 7569, 1788: 7570, 1789: 7573, 1790: 7580, 1791: 7581, 1792: 7584, 1793: 7585, 1794: 7586, 1795: 7587, 1796: 7589, 1797: 7590, 1798: 7591, 1799: 7594, 1800: 7595, 1801: 7597, 1802: 7598, 1803: 7600, 1804: 7601, 1805: 7605, 1806: 7608, 1807: 7609, 1808: 7610, 1809: 7611, 1810: 7613, 1811: 7617, 1812: 7618, 1813: 7619, 1814: 7621, 1815: 7622, 1816: 7623, 1817: 7628, 1818: 7629, 1819: 7630, 1820: 7631, 1821: 7632, 1822: 7633, 1823: 7634, 1824: 7635, 1825: 7636, 1826: 7637, 1827: 7638, 1828: 7639, 1829: 7640, 1830: 7641, 1831: 7642, 1832: 7643, 1833: 7644, 1834: 7645, 1835: 7646, 1836: 7647, 1837: 7650, 1838: 7654, 1839: 7657, 1840: 7659, 1841: 7660, 1842: 7661, 1843: 7662, 1844: 7663, 1845: 7664, 1846: 7665, 1847: 7667, 1848: 7670, 1849: 7671, 1850: 7673, 1851: 7674, 1852: 7676, 1853: 7678, 1854: 7679, 1855: 7680, 1856: 7681, 1857: 7682, 1858: 7683, 1859: 7685, 1860: 7688, 1861: 7689, 1862: 7690, 1863: 7692, 1864: 7693, 1865: 7695, 1866: 7696, 1867: 7697, 1868: 7698, 1869: 7699, 1870: 7700, 1871: 7701, 1872: 7705, 1873: 7707, 1874: 7708, 1875: 7709, 1876: 7711, 1877: 7712, 1878: 7713, 1879: 7714, 1880: 7716, 1881: 7717, 1882: 7719, 1883: 7720, 1884: 7724, 1885: 7725, 1886: 7726, 1887: 7727, 1888: 7728, 1889: 7729, 1890: 7730, 1891: 7731, 1892: 7733, 1893: 7734, 1894: 7735, 1895: 7736, 1896: 7737, 1897: 7738, 1898: 7739, 1899: 7741, 1900: 7743, 1901: 7744, 1902: 7745, 1903: 7746, 1904: 7747, 1905: 7748, 1906: 7749, 1907: 7750, 1908: 7751, 1909: 7754, 1910: 7755, 1911: 7756, 1912: 7757, 1913: 7758, 1914: 7759, 1915: 7761, 1916: 7762, 1917: 7763, 1918: 7764, 1919: 7765, 1920: 7767, 1921: 7768, 1922: 7771, 1923: 7773, 1924: 7775, 1925: 7776, 1926: 7779, 1927: 7780, 1928: 7781, 1929: 7782, 1930: 7788, 1931: 7789, 1932: 7792, 1933: 7793, 1934: 7796, 1935: 7815, 1936: 7816, 1937: 7818, 1938: 7820, 1939: 7821, 1940: 7822, 1941: 7823, 1942: 7824, 1943: 7825, 1944: 7826, 1945: 7827, 1946: 7828, 1947: 7829, 1948: 7830, 1949: 7831, 1950: 7835, 1951: 7836, 1952: 7837, 1953: 7838, 1954: 7842, 1955: 7844, 1956: 7845, 1957: 7846, 1958: 7847, 1959: 7848, 1960: 7849, 1961: 7851, 1962: 7859, 1963: 7861, 1964: 7862, 1965: 7869, 1966: 7873, 1967: 7881, 1968: 7882, 1969: 7883, 1970: 7884, 1971: 7885, 1972: 7886, 1973: 7887, 1974: 7888, 1975: 7890, 1976: 7891, 1977: 7894, 1978: 7895, 1979: 7899, 1980: 7901, 1981: 7902, 1982: 7903, 1983: 7904, 1984: 7905, 1985: 7906, 1986: 7907, 1987: 7908, 1988: 7911, 1989: 7912, 1990: 7913, 1991: 7914, 1992: 7915, 1993: 7916, 1994: 7917, 1995: 7918, 1996: 7921, 1997: 7922, 1998: 7924, 1999: 7925, 2000: 7928, 2001: 7930, 2002: 7931, 2003: 7932, 2004: 7933, 2005: 7935, 2006: 7936, 2007: 7937, 2008: 7939, 2009: 7940, 2010: 7941, 2011: 7943, 2012: 7944, 2013: 7945, 2014: 7946, 2015: 7947, 2016: 7948, 2017: 7949, 2018: 7951, 2019: 7952, 2020: 7953, 2021: 7954, 2022: 7957, 2023: 7960, 2024: 7962, 2025: 7964, 2026: 7965, 2027: 7966, 2028: 7967, 2029: 7968, 2030: 7969, 2031: 7971, 2032: 7979, 2033: 7980, 2034: 7983, 2035: 7985, 2036: 7988, 2037: 7989, 2038: 7992, 2039: 7993, 2040: 7994, 2041: 7996, 2042: 7998, 2043: 8000, 2044: 8001}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping.keys())[list(mapping.values()).index(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = np.zeros((50000,200,2045),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target in enumerate(summarytok):\n",
    "    for n, word in enumerate(target):\n",
    "        decoder_target[i,n,list(mapping.keys())[list(mapping.values()).index(word)]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEGNTH = 512\n",
    "NUM_WORDS = 2064 #본문 기사 내 가장 많이 사용된 3000단어?(or 전체 단어수로 할지 미정)\n",
    "VECTOR_SIZE = 768\n",
    "MAX_SUMMARIZATION_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 512)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200, 2045)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_kobert_model = get_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kobert_convert(integer_encoding, kobert_model):\n",
    "  '''정수 인코딩된 자료를 pytorch kobert 모델 통과해서 tensorflow의 tensor로 변환'''\n",
    "  return tf.convert_to_tensor(kobert_model(torch.LongTensor(integer_encoding))[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Input, Dense, dot, concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Attention():\n",
    "    def __init__(self):\n",
    "        self.max_length = 512\n",
    "        self.VECTOR_SIZE = 768\n",
    "        self.max_summary_length = 200\n",
    "        self.num_words = 2045\n",
    "        \n",
    "        self.sos =  2\n",
    "        self.eos =  3\n",
    "        \n",
    "        self.optimizer = Adam()\n",
    "        \n",
    "        encoder_inputs = Input(shape=(self.max_length,self.VECTOR_SIZE))\n",
    "        decoder_inputs = Input(shape=(self.max_summary_length,self.VECTOR_SIZE))\n",
    "        \n",
    "        self.att = self.build_att()\n",
    "\n",
    "        self.att.compile(loss='categorical_crossentropy', optimizer=self.optimizer)\n",
    "        print(self.att.summary())\n",
    "        \n",
    "        \n",
    "    def build_att(self):\n",
    "        def lstm(inputs, hs, seq=True, initial=None):\n",
    "            output,h,c = LSTM(hs, return_state=True, return_sequences=seq)(inputs, initial_state=initial) \n",
    "            #return_seq=False & return_state=True: return only last h, c\n",
    "            #return_seq=Ture & return_state=True: return all h, c\n",
    "            return output, h, c\n",
    "        \n",
    "        def fc(n_h_layers, inputs, hn):\n",
    "            for _ in range(n_h_layers):\n",
    "                d = Dense(hn, activation='tanh')(inputs)\n",
    "            if n_h_layers==0: \n",
    "                d = inputs\n",
    "            output = Dense(hn, activation='softmax')(d)\n",
    "            #모든 2064개 단어에 대한 확률값 (해당 위치에서의)\n",
    "            return output\n",
    "        \n",
    "        #(encoder input) already embedded from koBERT(vector size 만큼)\n",
    "        encoder_inputs = Input(shape=(self.max_length,self.VECTOR_SIZE))\n",
    "        encoder_outputs, h, c = lstm(encoder_inputs, 256)  #Discard encoder outputs\n",
    "        print(encoder_outputs)\n",
    "        init_states = [h,c]\n",
    "        \n",
    "        decoder_inputs = Input(shape=(self.max_summary_length,self.VECTOR_SIZE))\n",
    "        decoder_outputs, _, _ = lstm(decoder_inputs, 256, initial=init_states) #Discard encoder outputs\n",
    "        \n",
    "        value = Dense(5000, activation='tanh')(encoder_outputs)\n",
    "        query = Dense(5000, activation='tanh')(decoder_outputs)\n",
    "        print(value, query) #300x5000 두개\n",
    "        \n",
    "        attention = dot([query, value],axes=[2,2])\n",
    "        print(attention) #300x300\n",
    "        \n",
    "        attention_softmaxed = fc(0, attention, self.max_length)\n",
    "        print(attention_softmaxed) #300x300\n",
    "        print(encoder_outputs)\n",
    "        \n",
    "        weighted = dot([attention_softmaxed, encoder_outputs], axes=[2,1]) #give weights to encoder outputs(=각 토큰)\n",
    "        print(attention_softmaxed)\n",
    "        \n",
    "        print(weighted)\n",
    "        \n",
    "        decoder_for_final = concatenate([weighted, decoder_outputs]) #weighted token(2064x256) + decoder output(2064x256)\n",
    "        #or add? 둘중에 성능좋은거 고르기\n",
    "        \n",
    "        decoder_final = fc(1, decoder_for_final, self.num_words)\n",
    "        print(decoder_final)\n",
    "        \n",
    "        mod = Model([encoder_inputs, decoder_inputs], decoder_final) \n",
    "        return mod\n",
    "    \n",
    "    #Get data of batch size\n",
    "    def load_batch(self, batch_size=32):\n",
    "        self.n_batches = int(55000/32)\n",
    "        for i in range(self.n_batches):\n",
    "            batch_e = encoder_input[i*batch_size:(i+1)*batch_size]\n",
    "            batch_d = decoder_input[i*batch_size:(i+1)*batch_size]\n",
    "            batch_d_o = decoder_target[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            enc_ins, dec_ins, dec_out = [],[],[]\n",
    "            for enc_in, dec_in, dec_o in zip(batch_e, batch_d, batch_d_o):\n",
    "                enc_ins.append(enc_in)\n",
    "                dec_ins.append(dec_in)\n",
    "                dec_out.append(dec_o)\n",
    "\n",
    "            yield enc_ins, dec_ins, dec_out\n",
    "    \n",
    "    #train model\n",
    "    def train(self, epochs, batch_size = 32):\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (enc_batch, dec_batch, dec_out_batch) in enumerate(self.load_batch(batch_size)):\n",
    "                \n",
    "                enc_batch = kobert_convert(enc_batch, pytorch_kobert_model)\n",
    "                dec_batch = kobert_convert(dec_batch, pytorch_kobert_model)\n",
    "                \n",
    "                if batch_i%100==0:\n",
    "                    print(np.array(enc_batch).shape, np.array(dec_batch).shape, np.array(dec_out_batch).shape)\n",
    "                \n",
    "                enc_batch = np.array(enc_batch)\n",
    "                dec_batch = np.array(dec_batch)\n",
    "                dec_out_batch = np.array(dec_out_batch)\n",
    "                \n",
    "                att_loss = self.att.train_on_batch([enc_batch, dec_batch], dec_out_batch)\n",
    "                \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                \n",
    "                if batch_i%100==0:\n",
    "                    print(\"[Epoch %d/%d] [Batch %d/%d] Loss: %05f Time:%s\"%(epoch, epochs, batch_i, self.n_batches, att_loss, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_2/Identity:0\", shape=(None, 512, 256), dtype=float32)\n",
      "Tensor(\"dense_5/Identity:0\", shape=(None, 512, 5000), dtype=float32) Tensor(\"dense_6/Identity:0\", shape=(None, 200, 5000), dtype=float32)\n",
      "Tensor(\"dot_2/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"dense_7/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"lstm_2/Identity:0\", shape=(None, 512, 256), dtype=float32)\n",
      "Tensor(\"dense_7/Identity:0\", shape=(None, 200, 512), dtype=float32)\n",
      "Tensor(\"dot_3/Identity:0\", shape=(None, 200, 256), dtype=float32)\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Tensor(\"dense_9/Identity:0\", shape=(None, 200, 2045), dtype=float32)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 512, 768)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 200, 768)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512, 256), ( 1049600     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 200, 256), ( 1049600     input_8[0][0]                    \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200, 5000)    1285000     lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512, 5000)    1285000     lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 200, 512)     0           dense_6[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200, 512)     262656      dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 200, 256)     0           dense_7[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 512)     0           dot_3[0][0]                      \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 200, 2045)    1049085     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 200, 2045)    4184070     dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,165,011\n",
      "Trainable params: 10,165,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq_Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 512, 768) (64, 200, 768) (64, 200, 2045)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_6766 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 0/1718] Loss: 7.603610 Time:0:00:30.877848\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "(64, 512, 768) (64, 200, 768) (64, 200, 2045)\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[Epoch 0/10] [Batch 100/1718] Loss: 1.054415 Time:0:34:27.396638\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
